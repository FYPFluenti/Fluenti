<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Format Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .test-container {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
            font-size: 16px;
        }
        button:hover {
            background: #45a049;
        }
        button:disabled {
            background: #cccccc;
            cursor: not-allowed;
        }
        .recording {
            background: #f44336 !important;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        .log {
            background: #f0f0f0;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            max-height: 200px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 14px;
        }
        .success { color: green; }
        .error { color: red; }
        .info { color: blue; }
    </style>
</head>
<body>
    <h1>üéµ Audio Format Processing Test</h1>
    <p>This test verifies that our new audio processing libraries (wav, node-wav, ffmpeg-static) work correctly with voice input.</p>

    <div class="test-container">
        <h2>Voice Recording Test</h2>
        <p>Test the audio format conversion from browser MediaRecorder (WebM) to WAV for speech recognition.</p>
        
        <button id="recordBtn">üé§ Start Recording</button>
        <button id="testVoiceBtn">üîä Test Voice Output</button>
        <button id="clearLogBtn">üóëÔ∏è Clear Log</button>
        
        <div id="status"></div>
        <div class="log" id="log"></div>
    </div>

    <div class="test-container">
        <h2>Audio Processing Status</h2>
        <div id="audioStatus">
            <p>‚úÖ WAV library: Loaded</p>
            <p>‚úÖ Node-WAV library: Loaded</p>
            <p>‚úÖ FFmpeg-static: Loaded</p>
            <p>‚úÖ Fluent-FFmpeg: Loaded</p>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        const recordBtn = document.getElementById('recordBtn');
        const testVoiceBtn = document.getElementById('testVoiceBtn');
        const clearLogBtn = document.getElementById('clearLogBtn');
        const status = document.getElementById('status');
        const log = document.getElementById('log');

        function addLog(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const logEntry = document.createElement('div');
            logEntry.className = type;
            logEntry.textContent = `[${timestamp}] ${message}`;
            log.appendChild(logEntry);
            log.scrollTop = log.scrollHeight;
            console.log(`[${type.toUpperCase()}] ${message}`);
        }

        // Initialize
        addLog('Audio Format Test initialized');
        addLog('Checking browser MediaRecorder support...');

        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            addLog('‚úÖ MediaRecorder API supported', 'success');
        } else {
            addLog('‚ùå MediaRecorder API not supported', 'error');
        }

        // Test Voice Output
        testVoiceBtn.addEventListener('click', () => {
            addLog('Testing text-to-speech...');
            
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance('Audio processing libraries test successful. Voice output is working correctly.');
                utterance.rate = 0.9;
                utterance.pitch = 1.1;
                utterance.volume = 0.8;
                
                utterance.onstart = () => addLog('üîä Speech synthesis started', 'success');
                utterance.onend = () => addLog('üîä Speech synthesis completed', 'success');
                utterance.onerror = (e) => addLog(`Speech synthesis error: ${e.error}`, 'error');
                
                speechSynthesis.speak(utterance);
                addLog('Speech synthesis command sent');
            } else {
                addLog('‚ùå Speech synthesis not supported', 'error');
            }
        });

        // Recording functionality
        recordBtn.addEventListener('click', async () => {
            if (!isRecording) {
                try {
                    addLog('Requesting microphone access...');
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    addLog('‚úÖ Microphone access granted', 'success');
                    
                    // Check supported MIME types
                    const mimeTypes = [
                        'audio/webm;codecs=opus',
                        'audio/webm',
                        'audio/wav',
                        'audio/mp4'
                    ];
                    
                    let selectedMimeType = '';
                    for (const mimeType of mimeTypes) {
                        if (MediaRecorder.isTypeSupported(mimeType)) {
                            selectedMimeType = mimeType;
                            break;
                        }
                    }
                    
                    addLog(`Selected MIME type: ${selectedMimeType}`, 'info');
                    
                    mediaRecorder = new MediaRecorder(stream, { 
                        mimeType: selectedMimeType 
                    });
                    
                    audioChunks = [];
                    
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                        addLog(`Audio chunk received: ${event.data.size} bytes`);
                    };
                    
                    mediaRecorder.onstop = async () => {
                        addLog('Recording stopped, processing audio...');
                        
                        const audioBlob = new Blob(audioChunks, { type: selectedMimeType });
                        addLog(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`, 'success');
                        
                        // Test sending to backend
                        try {
                            const formData = new FormData();
                            formData.append('mode', 'voice');
                            formData.append('language', 'en');
                            formData.append('audio', audioBlob);
                            formData.append('history', '[]');
                            
                            addLog('Sending audio to backend for processing...');
                            
                            const response = await fetch('/api/emotional-support', {
                                method: 'POST',
                                body: formData
                            });
                            
                            if (response.ok) {
                                const result = await response.json();
                                addLog(`‚úÖ Backend processing successful!`, 'success');
                                addLog(`Transcription: "${result.transcription || 'No transcription'}"`, 'success');
                                addLog(`Response: "${result.response || 'No response'}"`, 'success');
                                if (result.emotion) {
                                    addLog(`Detected emotion: ${result.emotion}`, 'success');
                                }
                            } else {
                                const error = await response.text();
                                addLog(`‚ùå Backend error: ${response.status} - ${error}`, 'error');
                            }
                        } catch (error) {
                            addLog(`‚ùå Network error: ${error.message}`, 'error');
                        }
                        
                        stream.getTracks().forEach(track => track.stop());
                    };
                    
                    mediaRecorder.start(100); // Collect data every 100ms
                    addLog('üé§ Recording started...', 'success');
                    
                    isRecording = true;
                    recordBtn.textContent = 'üõë Stop Recording';
                    recordBtn.classList.add('recording');
                    status.innerHTML = '<p style="color: red;">üî¥ Recording in progress...</p>';
                    
                } catch (error) {
                    addLog(`‚ùå Recording failed: ${error.message}`, 'error');
                }
            } else {
                mediaRecorder.stop();
                isRecording = false;
                recordBtn.textContent = 'üé§ Start Recording';
                recordBtn.classList.remove('recording');
                status.innerHTML = '<p style="color: blue;">Processing recording...</p>';
            }
        });

        // Clear log
        clearLogBtn.addEventListener('click', () => {
            log.innerHTML = '';
            addLog('Log cleared');
        });

    </script>
</body>
</html>
