import fetch from 'node-fetch';
import FormData from 'form-data';
import fs from 'fs';
import path from 'path';

const SERVER_URL = 'http://localhost:3001';

async function testVoiceIntegration() {
  console.log('ğŸš€ Starting End-to-End Voice Integration Test\n');

  try {
    // Test 1: Create a user for authentication
    console.log('ğŸ“‹ Test 1: User Authentication Setup');
    
    const signupResponse = await fetch(`${SERVER_URL}/api/auth/signup`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        firstName: 'Voice',
        lastName: 'Tester',
        email: 'voicetester@fluenti.test',
        password: 'testpass123',
        userType: 'adult',
        language: 'english'
      })
    });
    
    let authToken = null;
    if (signupResponse.ok) {
      const userData = await signupResponse.json();
      authToken = userData.authToken || userData.user?.id;
      console.log('âœ… User created successfully, token:', authToken);
    } else {
      // Try login if user exists
      console.log('â„¹ï¸  User might exist, trying login...');
      const loginResponse = await fetch(`${SERVER_URL}/api/auth/login`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          email: 'voicetester@fluenti.test',
          password: 'testpass123'
        })
      });
      
      if (loginResponse.ok) {
        const loginData = await loginResponse.json();
        authToken = loginData.authToken || loginData.user?.id;
        console.log('âœ… User logged in successfully, token:', authToken);
      }
    }
    
    if (!authToken) {
      console.log('âŒ Failed to get authentication token');
      return;
    }

    // Test 2: Voice Mode - Stressed Audio
    console.log('\nğŸ“‹ Test 2: Voice Mode with Stressed Audio');
    
    const audioPath = path.join(process.cwd(), 'server', 'test-audio', 'stressed_test.wav');
    if (!fs.existsSync(audioPath)) {
      console.log('âŒ Stressed audio file not found');
      return;
    }
    
    const formData = new FormData();
    formData.append('mode', 'voice');
    formData.append('language', 'en');
    formData.append('audio', fs.createReadStream(audioPath), 'voice.wav');
    formData.append('history', JSON.stringify([]));
    
    console.log('â³ Sending voice request...');
    const voiceResponse = await fetch(`${SERVER_URL}/api/emotional-support`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${authToken}`,
        ...formData.getHeaders()
      },
      body: formData
    });
    
    console.log('ğŸ“Š Voice Response Status:', voiceResponse.status);
    
    if (voiceResponse.ok) {
      const voiceData = await voiceResponse.json();
      console.log('\nğŸ‰ Voice Mode Test Results:');
      console.log('ğŸ¤ Transcription:', voiceData.transcription);
      console.log('ğŸ˜Š Detected Emotion:', voiceData.emotion?.emotion, `(${voiceData.confidence || voiceData.emotion?.score})`);
      console.log('ğŸ’¬ AI Response:', voiceData.response?.substring(0, 120) + '...');
      console.log('ğŸ” Emotion Source:', voiceData.emotionSource || 'text-only');
      console.log('ğŸŒ Language:', voiceData.language);
      console.log('ğŸ¯ Voice Mode:', voiceData.voiceMode);
      
      // Validation checks
      const isValidTranscription = voiceData.transcription && voiceData.transcription.toLowerCase().includes('stress');
      const hasValidEmotion = voiceData.emotion && voiceData.emotion.emotion;
      const hasResponse = voiceData.response && voiceData.response.length > 10;
      
      console.log('\nğŸ“‹ Validation Results:');
      console.log('âœ… STT Working:', isValidTranscription ? 'PASS' : 'FAIL');
      console.log('âœ… Emotion Detection:', hasValidEmotion ? 'PASS' : 'FAIL');
      console.log('âœ… Response Generation:', hasResponse ? 'PASS' : 'FAIL');
      
    } else {
      const errorText = await voiceResponse.text();
      console.log('âŒ Voice mode failed:', voiceResponse.status, errorText);
    }

    // Test 3: Text Mode (Chat Mode Test)
    console.log('\nğŸ“‹ Test 3: Text Mode (Chat Mode)');
    
    const textResponse = await fetch(`${SERVER_URL}/api/emotional-support`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${authToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        text: 'I am feeling very anxious about my upcoming presentation',
        mode: 'text',
        language: 'en',
        history: []
      })
    });
    
    console.log('ğŸ“Š Text Response Status:', textResponse.status);
    
    if (textResponse.ok) {
      const textData = await textResponse.json();
      console.log('\nğŸ‰ Text Mode Test Results:');
      console.log('ğŸ“ Input Text:', 'I am feeling very anxious about my upcoming presentation');
      console.log('ğŸ˜Š Detected Emotion:', textData.emotion?.emotion, `(${textData.confidence || textData.emotion?.score})`);
      console.log('ğŸ’¬ AI Response:', textData.response?.substring(0, 120) + '...');
      
      // Validation
      const hasValidEmotion = textData.emotion && (textData.emotion.emotion === 'anxious' || textData.emotion.emotion === 'anxiety');
      const hasResponse = textData.response && textData.response.length > 10;
      
      console.log('\nğŸ“‹ Text Mode Validation:');
      console.log('âœ… Text Processing:', textData.transcription ? 'PASS' : 'PASS (direct text)');
      console.log('âœ… Emotion Detection:', hasValidEmotion ? 'PASS' : `DETECTED: ${textData.emotion?.emotion}`);
      console.log('âœ… Response Generation:', hasResponse ? 'PASS' : 'FAIL');
      
    } else {
      const errorText = await textResponse.text();
      console.log('âŒ Text mode failed:', textResponse.status, errorText);
    }

    // Test 4: Performance & Debug Info
    console.log('\nğŸ“‹ Test 4: System Performance Check');
    console.log('âš¡ GPU Available: Check server logs for torch.cuda output');
    console.log('ğŸ Python Environment: Using virtual environment .venv');
    console.log('ğŸµ Audio Format: WAV files (673KB stressed, 880KB anxious)');
    console.log('â±ï¸ Expected Performance: ~20-60s first run (model loading), ~5-25s subsequent');

    console.log('\nğŸŠ End-to-End Voice Integration Test Complete!');

  } catch (error) {
    console.error('âŒ Test suite failed:', error);
  }
}

// Run the test
testVoiceIntegration();
