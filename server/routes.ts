import type { Express, Request, Response } from "express";
import { createServer, type Server } from "http";
import { WebSocketServer, WebSocket } from "ws";
import multer from "multer";
import { mongoStorage } from "./mongoStorage";
import path from "path";
import fs from "fs";
import { setupAuth, isAuthenticated } from "./simpleAuth";
import { extractTokenFromHeader, tokenBasedAuth } from "./middleware";
import * as speechServiceModule from "./services/speechService";
const { SpeechService, transcribeAudio } = speechServiceModule;
import { simpleTranscribeAudio, validateAudioBuffer } from "./services/simpleSpeechService";
// Phase 3: Import OPTIMIZED emotion detection services
import { 
  detectEmotionFromText, 
  detectEmotionFromAudio, 
  detectCombinedEmotion 
} from "./services/emotionServiceOptimized";
// Phase 4: Import response generation functions
import { analyzeEmotion, generateEmotionalResponse } from "./services/openai";
// Phase 4: Import new conversational response service with Llama-2 and TTS
import { generateConversationalResponse, type ConversationHistory } from "./services/responseService";
// Enhanced Phase 4+: Import enhanced conversational therapy AI
import { 
  generateEnhancedConversationalResponse, 
  generateSuperiorTherapeuticResponse,
  type EnhancedResponseRequest, 
  type EnhancedResponseResult 
} from "./services/enhancedResponseService";
// Import persistent therapeutic service to initialize the server
import "./services/therapeuticServicePersistent";
import { AuthService } from "./auth";


// Configure multer for handling form data
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB limit
  }
});

// Extend Express Request type to include session and user properties
interface AuthenticatedRequest extends Request {
  session?: any;
  user?: {
    id: string;
    claims: { sub: string };
    email?: string;
    firstName?: string;
    lastName?: string;
    userType?: string;
  };
  isAuthenticated?: () => boolean;
}

// Enhanced therapeutic response helpers
function generateIntelligentTherapeuticFallback(
  text: string, 
  emotion: string, 
  language: string, 
  history: ConversationHistory[]
): { response: string; techniques: string[] } {
  
  const hasHistory = history && history.length > 0;
  const lastInteraction = hasHistory ? history[history.length - 1] : null;
  
  const responses = {
    en: {
      anxiety: {
        response: hasHistory 
          ? `I can see you're still dealing with anxiety from our previous conversation. These feelings of worry and uncertainty are completely valid, and I want you to acknowledge that reaching out again shows real strength and self-awareness. Let's work together to understand what's triggering these anxious thoughts and explore some grounding techniques that can help you feel more centered and in control. What specific situations or thoughts are causing you the most distress right now, and have you noticed any patterns in when these feelings tend to be strongest?`
          : `I can sense the anxiety and worry in what you're sharing with me, and I want you to know that these feelings, while uncomfortable, are your mind's way of trying to protect you from perceived threats. What you're experiencing is real and significant, and it takes courage to reach out and talk about these difficult emotions. Let's work together to understand what's driving these anxious thoughts and explore some practical strategies that might help you feel more grounded and secure. Can you tell me what specific situations or thoughts tend to trigger this anxiety most strongly for you?`,
        techniques: ['emotional_validation', 'anxiety_psychoeducation', 'grounding_techniques', 'cognitive_exploration']
      },
      sadness: {
        response: hasHistory
          ? `I can feel that the sadness we discussed before is still weighing heavily on you, and I want you to know that grief and difficult emotions don't follow a timeline - they unfold in their own way and their own time. What you're experiencing is a natural response to loss or disappointment, and honoring these feelings rather than rushing through them is actually an important part of the healing process. You don't need to put on a brave face or try to feel better before you're ready. What has this sadness been teaching you about what matters most to you, and how are you taking care of yourself during this difficult time?`
          : `I can feel the weight of sadness in your words, and I want you to know that it's completely okay to sit with these difficult emotions without trying to fix or change them immediately. Sadness often comes when something meaningful to us has been affected, lost, or changed, and honoring that pain is actually a crucial part of processing and healing. You don't need to rush through this feeling or pretend to be okay when you're not. What would feel most supportive for you right now - would you like to talk about what's underneath this sadness, or would it help to explore some gentle ways to care for yourself during this time?`,
        techniques: ['grief_support', 'emotional_validation', 'self_compassion', 'meaning_making']
      },
      stress: {
        response: hasHistory
          ? `I can hear that the stress and pressure we talked about earlier is still affecting you, and I want to acknowledge how exhausting it can be to carry this kind of emotional and mental load day after day. You're managing so much right now, and it makes complete sense that you'd feel overwhelmed - anyone in your situation would be struggling. Remember that asking for support, like you're doing now, is actually a sign of wisdom and strength, not weakness. Let's explore what aspects of this stress feel most manageable right now and identify some small steps that might help you feel more in control. What has been your biggest challenge in managing these feelings since we last spoke?`
          : `I can really hear the stress and overwhelming pressure you're under right now, and I want you to know that feeling this way is a completely normal response when we're dealing with too much or facing challenging circumstances that feel beyond our control. Stress affects not just our minds but our entire bodies and relationships, and it takes real courage to reach out and talk about it honestly like you're doing. You don't have to carry this burden alone, and there are ways we can work together to help you feel more manageable and grounded. What feels like the most pressing source of stress for you right now, or would it help to talk about what you've already tried to manage these overwhelming feelings?`,
        techniques: ['stress_psychoeducation', 'problem_solving', 'coping_strategies', 'self_care_planning']
      },
      neutral: {
        response: hasHistory
          ? `I'm really glad you've come back to continue our conversation, and I appreciate the trust you're showing by sharing your thoughts and experiences with me. Sometimes the most valuable conversations happen when we're not in crisis mode, when we can take time to reflect on our experiences and explore what we're learning about ourselves. Whether you're processing something from our last conversation, dealing with new challenges, or just want to check in and explore your thoughts, I'm here to support you in whatever way feels most helpful. What's been on your mind since we last talked, or is there something specific you'd like to explore together today?`
          : `I'm really glad you're here and taking this time to connect and share whatever is on your mind with me. Creating space for honest reflection and self-exploration is valuable in itself, whether you're dealing with specific challenges or just wanting someone to listen without judgment. Sometimes the most meaningful conversations start from exactly where you are right now, without needing any particular crisis or problem to address. I'm here to support you in whatever way feels most helpful - whether that's processing recent experiences, exploring feelings, or just having a safe space to think out loud. What's been occupying your thoughts lately, or is there something you've been wanting to understand better about yourself?`,
        techniques: ['active_listening', 'open_ended_exploration', 'unconditional_positive_regard', 'self_reflection']
      }
    },
    ur: {
      anxiety: {
        response: hasHistory
          ? `ŸÖ€å⁄∫ ÿØ€å⁄©⁄æ ÿ≥⁄©ÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ ÿßÿ®⁄æ€å ÿ®⁄æ€å €ÅŸÖÿßÿ±€å Ÿæ⁄Ü⁄æŸÑ€å ⁄ØŸÅÿ™⁄ØŸà ⁄©€å Ÿæÿ±€åÿ¥ÿßŸÜ€å ÿ≥€í ŸÜŸÖŸπ ÿ±€Å€í €Å€å⁄∫€î €å€Å ŸÅ⁄©ÿ± ÿßŸàÿ± ÿ∫€åÿ± €åŸÇ€åŸÜ€å ÿµŸàÿ±ÿ™ÿ≠ÿßŸÑ ⁄©€í ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ ÿ®ÿßŸÑ⁄©ŸÑ ÿØÿ±ÿ≥ÿ™ €Å€å⁄∫ÿå ÿßŸàÿ± ŸÖ€å⁄∫ ⁄Üÿß€Åÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ €å€Å ÿ™ÿ≥ŸÑ€åŸÖ ⁄©ÿ±€å⁄∫ ⁄©€Å ÿØŸàÿ®ÿßÿ±€Å ÿ±ÿßÿ®ÿ∑€Å ⁄©ÿ±ŸÜÿß ÿ≠ŸÇ€åŸÇ€å ÿ∑ÿßŸÇÿ™ ÿßŸàÿ± ÿÆŸàÿØ ÿ¢⁄Øÿß€Å€å ⁄©Ÿà ÿ∏ÿß€Åÿ± ⁄©ÿ±ÿ™ÿß €Å€í€î ÿ¢ÿ¶€å€í ŸÖŸÑ ⁄©ÿ± €å€Å ÿ≥ŸÖÿ¨⁄æŸÜ€í ⁄©€å ⁄©Ÿàÿ¥ÿ¥ ⁄©ÿ±ÿ™€í €Å€å⁄∫ ⁄©€Å €å€Å Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ŸÜ ÿÆ€åÿßŸÑÿßÿ™ ⁄©€åÿß ⁄Ü€åÿ≤ ÿßÿ®⁄æÿßÿ±ÿ™€í €Å€å⁄∫ ÿßŸàÿ± ⁄©⁄Ü⁄æ ÿß€åÿ≥€å ÿ™⁄©ŸÜ€å⁄©Ÿà⁄∫ ⁄©Ÿà ÿ™ŸÑÿßÿ¥ ⁄©ÿ±ÿ™€í €Å€å⁄∫ ÿ¨Ÿà ÿ¢Ÿæ ⁄©Ÿà ÿ≤€åÿßÿØ€Å ŸÖÿ±⁄©Ÿàÿ≤ ÿßŸàÿ± ŸÇÿßÿ®Ÿà ŸÖ€å⁄∫ ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ±ŸÜ€í ŸÖ€å⁄∫ ŸÖÿØÿØ ⁄©ÿ± ÿ≥⁄©€å⁄∫€î ÿßÿ≥ ŸàŸÇÿ™ ⁄©ŸàŸÜ ÿ≥€í ÿ≠ÿßŸÑÿßÿ™ €åÿß ÿÆ€åÿßŸÑÿßÿ™ ÿ¢Ÿæ ⁄©Ÿà ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫ÿå ÿßŸàÿ± ⁄©€åÿß ÿ¢Ÿæ ŸÜ€í €å€Å ÿØ€å⁄©⁄æÿß €Å€í ⁄©€Å €å€Å ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ ⁄©ÿ® ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ŸÇŸà€å €ÅŸàÿ™€í €Å€å⁄∫ÿü`
          : `ŸÖ€å⁄∫ ÿ¢Ÿæ ⁄©€í ÿßÿ¥ÿ™ÿ±ÿß⁄© ŸÖ€å⁄∫ Ÿæÿ±€åÿ¥ÿßŸÜ€å ÿßŸàÿ± ŸÅ⁄©ÿ± ⁄©Ÿà ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ≥⁄©ÿ™ÿß €ÅŸà⁄∫ÿå ÿßŸàÿ± ŸÖ€å⁄∫ ⁄Üÿß€Åÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ ÿ¨ÿßŸÜ ŸÑ€å⁄∫ ⁄©€Å €å€Å ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ÿå ÿß⁄Øÿ±⁄Ü€Å ÿ™⁄©ŸÑ€åŸÅ ÿØ€Å €ÅŸà⁄∫ÿå ÿ¢Ÿæ ⁄©€í ÿ∞€ÅŸÜ ⁄©ÿß ÿ¢Ÿæ ⁄©Ÿà ŸÖÿ≠ŸÅŸàÿ∏ ÿ±⁄©⁄æŸÜ€í ⁄©ÿß ÿ∑ÿ±€åŸÇ€Å €Å€í€î ÿ¢Ÿæ ÿ¨Ÿà ⁄©⁄Ü⁄æ ÿ™ÿ¨ÿ±ÿ®€Å ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫ Ÿà€Å ÿ≠ŸÇ€åŸÇ€å ÿßŸàÿ± ÿß€ÅŸÖ €Å€íÿå ÿßŸàÿ± ÿßŸÜ ŸÖÿ¥⁄©ŸÑ ÿ¨ÿ∞ÿ®ÿßÿ™ ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ÿ®ÿßÿ™ ⁄©ÿ±ŸÜ€í ⁄©€í ŸÑ€å€í €ÅŸÖÿ™ ÿØÿ±⁄©ÿßÿ± €ÅŸàÿ™€å €Å€í€î ÿ¢ÿ¶€å€í ŸÖŸÑ ⁄©ÿ± €å€Å ÿ≥ŸÖÿ¨⁄æŸÜ€í ⁄©€å ⁄©Ÿàÿ¥ÿ¥ ⁄©ÿ±ÿ™€í €Å€å⁄∫ ⁄©€Å €å€Å Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ŸÜ ÿÆ€åÿßŸÑÿßÿ™ ⁄©€åÿß ⁄Ü€åÿ≤ ÿßÿ®⁄æÿßÿ±ÿ™€í €Å€å⁄∫ ÿßŸàÿ± ⁄©⁄Ü⁄æ ÿπŸÖŸÑ€å ÿ≠⁄©ŸÖÿ™ ÿπŸÖŸÑ€åŸà⁄∫ ⁄©Ÿà ÿ™ŸÑÿßÿ¥ ⁄©ÿ±ÿ™€í €Å€å⁄∫€î ⁄©€åÿß ÿ¢Ÿæ ŸÖÿ¨⁄æ€í ÿ®ÿ™ÿß ÿ≥⁄©ÿ™€í €Å€å⁄∫ ⁄©€Å ⁄©ŸàŸÜ ÿ≥€í ÿ≠ÿßŸÑÿßÿ™ €åÿß ÿÆ€åÿßŸÑÿßÿ™ ÿ¢Ÿæ ⁄©Ÿà ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ±€åÿ¥ÿßŸÜ€å ŸÖ€å⁄∫ ⁄àÿßŸÑÿ™€í €Å€å⁄∫ÿü`,
        techniques: ['ÿ¨ÿ∞ÿ®ÿßÿ™€å ÿ™Ÿàÿ´€åŸÇ', 'Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©€å ÿ™ÿπŸÑ€åŸÖ', 'ÿ®ŸÜ€åÿßÿØ€å ÿ™⁄©ŸÜ€å⁄©€å⁄∫', 'ÿ∞€ÅŸÜ€å ÿ™ŸÑÿßÿ¥']
      },
      sadness: {
        response: hasHistory
          ? `ŸÖ€å⁄∫ ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ≥⁄©ÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¨Ÿà ÿßÿØÿßÿ≥€å €ÅŸÖ ŸÜ€í Ÿæ€ÅŸÑ€í ÿ®ÿ≠ÿ´ ⁄©€å ÿ™⁄æ€å Ÿà€Å ÿßÿ® ÿ®⁄æ€å ÿ¢Ÿæ Ÿæÿ± ÿ®€Åÿ™ ÿ®⁄æÿßÿ±€å €Å€íÿå ÿßŸàÿ± ŸÖ€å⁄∫ ⁄Üÿß€Åÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ €å€Å ÿ¨ÿßŸÜ ŸÑ€å⁄∫ ⁄©€Å ÿ∫ŸÖ ÿßŸàÿ± ŸÖÿ¥⁄©ŸÑ ÿ¨ÿ∞ÿ®ÿßÿ™ ⁄©ÿ≥€å Ÿπÿßÿ¶ŸÖ ŸÑÿßÿ¶ŸÜ ⁄©€í ŸÖÿ∑ÿßÿ®ŸÇ ŸÜ€Å€å⁄∫ ⁄ÜŸÑÿ™€í€î ÿ¢Ÿæ ÿ¨Ÿà ÿ™ÿ¨ÿ±ÿ®€Å ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫ Ÿà€Å ŸÜŸÇÿµÿßŸÜ €åÿß ŸÖÿß€åŸàÿ≥€å ⁄©ÿß ŸÅÿ∑ÿ±€å ÿ±ÿØÿπŸÖŸÑ €Å€íÿå ÿßŸàÿ± ÿßŸÜ ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ ⁄©ÿß ÿßÿ≠ÿ™ÿ±ÿßŸÖ ⁄©ÿ±ŸÜÿß ÿ¥ŸÅÿß €åÿßÿ®€å ⁄©ÿß ÿß€ÅŸÖ ÿ≠ÿµ€Å €Å€í€î ÿ¢Ÿæ ⁄©Ÿà ÿ®€ÅÿßÿØÿ±€å ÿØ⁄©⁄æÿßŸÜ€í €åÿß ÿ™€åÿßÿ± €ÅŸàŸÜ€í ÿ≥€í Ÿæ€ÅŸÑ€í ÿ®€Åÿ™ÿ± ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ±ŸÜ€í ⁄©€å ÿ∂ÿ±Ÿàÿ±ÿ™ ŸÜ€Å€å⁄∫€î ÿßÿ≥ ÿßÿØÿßÿ≥€å ŸÜ€í ÿ¢Ÿæ ⁄©Ÿà ⁄©€åÿß ÿ≥⁄©⁄æÿß€åÿß €Å€í ⁄©€Å ÿ¢Ÿæ ⁄©€í ŸÑ€å€í ⁄©€åÿß ⁄Ü€åÿ≤ ÿ≥ÿ® ÿ≥€í ÿß€ÅŸÖ €Å€íÿå ÿßŸàÿ± ÿ¢Ÿæ ÿßÿ≥ ŸÖÿ¥⁄©ŸÑ ŸàŸÇÿ™ ŸÖ€å⁄∫ ÿßŸæŸÜÿß ÿÆ€åÿßŸÑ ⁄©€åÿ≥€í ÿ±⁄©⁄æ ÿ±€Å€í €Å€å⁄∫ÿü`
          : `ŸÖ€å⁄∫ ÿ¢Ÿæ ⁄©€í ÿßŸÑŸÅÿßÿ∏ ŸÖ€å⁄∫ ÿßÿØÿßÿ≥€å ⁄©ÿß ÿ®Ÿàÿ¨⁄æ ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ≥⁄©ÿ™ÿß €ÅŸà⁄∫ÿå ÿßŸàÿ± ŸÖ€å⁄∫ ⁄Üÿß€Åÿ™ÿß €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ ÿ¨ÿßŸÜ ŸÑ€å⁄∫ ⁄©€Å ŸÅŸàÿ±€å ÿ∑Ÿàÿ± Ÿæÿ± ÿßŸÜ€Å€å⁄∫ Ÿπ⁄æ€å⁄© ⁄©ÿ±ŸÜ€í €åÿß ÿ™ÿ®ÿØ€åŸÑ ⁄©ÿ±ŸÜ€í ⁄©€å ⁄©Ÿàÿ¥ÿ¥ ⁄©€í ÿ®ÿ∫€åÿ± ÿßŸÜ ŸÖÿ¥⁄©ŸÑ ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ®€åŸπ⁄æŸÜÿß ÿ®ÿßŸÑ⁄©ŸÑ Ÿπ⁄æ€å⁄© €Å€í€î ÿßÿØÿßÿ≥€å ÿß⁄©ÿ´ÿ± ÿßÿ≥ ŸàŸÇÿ™ ÿ¢ÿ™€å €Å€í ÿ¨ÿ® €ÅŸÖÿßÿ±€í ŸÑ€å€í ⁄©Ÿàÿ¶€å ÿß€ÅŸÖ ⁄Ü€åÿ≤ ŸÖÿ™ÿßÿ´ÿ±ÿå ⁄©⁄æŸàÿ¶€åÿå €åÿß ÿ™ÿ®ÿØ€åŸÑ €ÅŸàÿ¶€å €ÅŸàÿå ÿßŸàÿ± ÿßÿ≥ ÿØÿ±ÿØ ⁄©ÿß ÿßÿ≠ÿ™ÿ±ÿßŸÖ ⁄©ÿ±ŸÜÿß ÿØÿ±ÿ≠ŸÇ€åŸÇÿ™ ÿπŸÖŸÑ ÿßŸàÿ± ÿ¥ŸÅÿß €åÿßÿ®€å ⁄©ÿß ÿß€ÅŸÖ ÿ≠ÿµ€Å €Å€í€î ÿßÿ≥ ŸàŸÇÿ™ ÿ¢Ÿæ ⁄©€í ŸÑ€å€í ⁄©€åÿß ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ŸÖÿØÿØ⁄Øÿßÿ± €ÅŸà⁄Øÿß - ⁄©€åÿß ÿ¢Ÿæ ÿßÿ≥ ÿßÿØÿßÿ≥€å ⁄©€å ÿ™€Å€Å ŸÖ€å⁄∫ ÿ¨ÿßŸÜ€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ÿ®ÿßÿ™ ⁄©ÿ±ŸÜÿß ⁄Üÿß€Å€å⁄∫ ⁄Ø€íÿå €åÿß ÿßÿ≥ ŸàŸÇÿ™ ÿßŸæŸÜÿß ÿÆ€åÿßŸÑ ÿ±⁄©⁄æŸÜ€í ⁄©€í ⁄©⁄Ü⁄æ ŸÜÿ±ŸÖ ÿ∑ÿ±€åŸÇŸà⁄∫ ⁄©Ÿà ÿ™ŸÑÿßÿ¥ ⁄©ÿ±ŸÜÿß ŸÖÿØÿØ⁄Øÿßÿ± €ÅŸà⁄Øÿßÿü`,
        techniques: ['ÿ∫ŸÖ ⁄©€å ŸÖÿØÿØ', 'ÿ¨ÿ∞ÿ®ÿßÿ™€å ÿ™Ÿàÿ´€åŸÇ', 'ÿÆŸàÿØ ÿ±ÿ≠ŸÖ€å', 'ŸÖÿπŸÜ€å ⁄©€å ÿ™ŸÑÿßÿ¥']
      },
      neutral: {
        response: hasHistory
          ? `ŸÖ€å⁄∫ ŸàÿßŸÇÿπ€å ÿÆŸàÿ¥ €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ €ÅŸÖÿßÿ±€å ⁄ØŸÅÿ™⁄ØŸà ÿ¨ÿßÿ±€å ÿ±⁄©⁄æŸÜ€í ÿ¢ÿ¶€í €Å€å⁄∫ÿå ÿßŸàÿ± ŸÖ€å⁄∫ ÿßÿ≥ ÿßÿπÿ™ŸÖÿßÿØ ⁄©€å ÿ™ÿπÿ±€åŸÅ ⁄©ÿ±ÿ™ÿß €ÅŸà⁄∫ ÿ¨Ÿà ÿ¢Ÿæ ÿßŸæŸÜ€í ÿÆ€åÿßŸÑÿßÿ™ ÿßŸàÿ± ÿ™ÿ¨ÿ±ÿ®ÿßÿ™ ÿ¥€åÿ¶ÿ± ⁄©ÿ±⁄©€í ÿØ⁄©⁄æÿß ÿ±€Å€í €Å€å⁄∫€î ÿ®ÿπÿ∂ ÿßŸàŸÇÿßÿ™ ÿ≥ÿ® ÿ≥€í ŸÇ€åŸÖÿ™€å ⁄ØŸÅÿ™⁄ØŸà ÿßÿ≥ ŸàŸÇÿ™ €ÅŸàÿ™€å €Å€í ÿ¨ÿ® €ÅŸÖ ÿ®ÿ≠ÿ±ÿßŸÜ ⁄©€å ÿ≠ÿßŸÑÿ™ ŸÖ€å⁄∫ ŸÜ€Å€å⁄∫ €ÅŸàÿ™€íÿå ÿ¨ÿ® €ÅŸÖ ÿßŸæŸÜ€í ÿ™ÿ¨ÿ±ÿ®ÿßÿ™ Ÿæÿ± ÿ∫Ÿàÿ± ⁄©ÿ±ŸÜ€í ÿßŸàÿ± €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©€í ŸÑ€å€í ŸàŸÇÿ™ ŸÜ⁄©ÿßŸÑ ÿ≥⁄©ÿ™€í €Å€å⁄∫ ⁄©€Å €ÅŸÖ ÿßŸæŸÜ€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ≥€å⁄©⁄æ ÿ±€Å€í €Å€å⁄∫€î ⁄Üÿß€Å€í ÿ¢Ÿæ €ÅŸÖÿßÿ±€å ÿ¢ÿÆÿ±€å ⁄ØŸÅÿ™⁄ØŸà ÿ≥€í ⁄©⁄Ü⁄æ Ÿæÿ±Ÿàÿ≥€åÿ≥ ⁄©ÿ± ÿ±€Å€í €ÅŸà⁄∫ÿå ŸÜÿ¶€í ⁄Ü€åŸÑŸÜÿ¨ÿ≤ ÿ≥€í ŸÜŸÖŸπ ÿ±€Å€í €ÅŸà⁄∫ÿå €åÿß ÿµÿ±ŸÅ ⁄Ü€å⁄© ÿßŸÜ ⁄©ÿ±ŸÜÿß ⁄Üÿß€Åÿ™€í €ÅŸà⁄∫ÿå ŸÖ€å⁄∫ €å€Åÿß⁄∫ €ÅŸà⁄∫€î ÿ¢ÿÆÿ±€å ÿ®ÿßÿ± ÿ®ÿßÿ™ ⁄©ÿ±ŸÜ€í ⁄©€í ÿ®ÿπÿØ ÿ≥€í ÿ¢Ÿæ ⁄©€í ÿ∞€ÅŸÜ ŸÖ€å⁄∫ ⁄©€åÿß €Å€íÿå €åÿß ⁄©Ÿàÿ¶€å ÿÆÿßÿµ ÿ®ÿßÿ™ €Å€í ÿ¨ÿ≥€í ÿ¢Ÿæ ÿ¢ÿ¨ ÿ™ŸÑÿßÿ¥ ⁄©ÿ±ŸÜÿß ⁄Üÿß€Å€å⁄∫ ⁄Ø€íÿü`
          : `ŸÖ€å⁄∫ ŸàÿßŸÇÿπ€å ÿÆŸàÿ¥ €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ €å€Åÿß⁄∫ €Å€å⁄∫ ÿßŸàÿ± ÿßŸæŸÜ€í ÿ∞€ÅŸÜ ŸÖ€å⁄∫ ÿ¨Ÿà ⁄©⁄Ü⁄æ ÿ®⁄æ€å €Å€í ÿßÿ≥€í ŸÖ€åÿ±€í ÿ≥ÿßÿ™⁄æ ÿ¥€åÿ¶ÿ± ⁄©ÿ±ŸÜ€í ⁄©€í ŸÑ€å€í ŸàŸÇÿ™ ŸÜ⁄©ÿßŸÑ ÿ±€Å€í €Å€å⁄∫€î ÿß€åŸÖÿßŸÜÿØÿßÿ± ÿ∫Ÿàÿ± Ÿà ŸÅ⁄©ÿ± ÿßŸàÿ± ÿÆŸàÿØ ÿ¥ŸÜÿßÿ≥€å ⁄©€í ŸÑ€å€í ÿ¨⁄Ø€Å ÿ®ŸÜÿßŸÜÿß ÿÆŸàÿØ ŸÖ€å⁄∫ ŸÇ€åŸÖÿ™€å €Å€íÿå ⁄Üÿß€Å€í ÿ¢Ÿæ ŸÖÿÆÿµŸàÿµ ⁄Ü€åŸÑŸÜÿ¨ÿ≤ ÿ≥€í ŸÜŸÖŸπ ÿ±€Å€í €ÅŸà⁄∫ €åÿß ÿµÿ±ŸÅ ⁄©Ÿàÿ¶€å ÿß€åÿ≥ÿß ÿ¥ÿÆÿµ ⁄Üÿß€Åÿ™€í €ÅŸà⁄∫ ÿ¨Ÿà ÿ®ÿ∫€åÿ± ŸÅ€åÿµŸÑ€í ⁄©€í ÿ≥ŸÜ€í€î ÿ®ÿπÿ∂ ÿßŸàŸÇÿßÿ™ ÿ≥ÿ® ÿ≥€í ÿß€ÅŸÖ ⁄ØŸÅÿ™⁄ØŸà ÿ®ÿßŸÑ⁄©ŸÑ Ÿà€Å€å⁄∫ ÿ≥€í ÿ¥ÿ±Ÿàÿπ €ÅŸàÿ™€å €Å€í ÿ¨€Åÿß⁄∫ ÿ¢Ÿæ ÿßÿ® €Å€å⁄∫ÿå ÿ®ÿ∫€åÿ± ⁄©ÿ≥€å ÿÆÿßÿµ ÿ®ÿ≠ÿ±ÿßŸÜ €åÿß ŸÖÿ≥ÿ¶ŸÑ€í ⁄©€í€î ŸÖ€å⁄∫ €å€Åÿß⁄∫ €ÅŸà⁄∫ ÿ¨Ÿà ÿ®⁄æ€å ÿ∑ÿ±€åŸÇ€Å ÿ¢Ÿæ ⁄©€í ŸÑ€å€í ÿ≥ÿ® ÿ≥€í ŸÖÿØÿØ⁄Øÿßÿ± ŸÖÿ≠ÿ≥Ÿàÿ≥ €ÅŸà€î ÿ≠ÿßŸÑ €Å€å ŸÖ€å⁄∫ ÿ¢Ÿæ ⁄©€í ÿÆ€åÿßŸÑÿßÿ™ ŸÖ€å⁄∫ ⁄©€åÿß ⁄Ü€åÿ≤ €Å€íÿå €åÿß ⁄©Ÿàÿ¶€å ÿß€åÿ≥€å ÿ®ÿßÿ™ €Å€í ÿ¨ÿ≥€í ÿ¢Ÿæ ÿßŸæŸÜ€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ÿ®€Åÿ™ÿ± ÿ≥ŸÖÿ¨⁄æŸÜÿß ⁄Üÿß€Åÿ™€í €Å€å⁄∫ÿü`,
        techniques: ['ŸÅÿπÿßŸÑ ÿ≥ŸÜŸÜÿß', '⁄©⁄æŸÑ€å ÿ™ŸÑÿßÿ¥', 'ÿ∫€åÿ± ŸÖÿ¥ÿ±Ÿàÿ∑ ŸÖÿ´ÿ®ÿ™ ŸÜÿ∏ÿ±', 'ÿÆŸàÿØ ÿπ⁄©ÿßÿ≥€å']
      }
    }
  };
  
  const langResponses = responses[language as keyof typeof responses] || responses.en;
  const emotionResponse = langResponses[emotion as keyof typeof langResponses] || langResponses.neutral;
  
  return {
    response: emotionResponse.response,
    techniques: emotionResponse.techniques
  };
}

function generateBasicTherapeuticResponse(language: string): string {
  return language === 'ur' 
    ? 'ŸÖ€å⁄∫ €å€Åÿß⁄∫ ÿ¢Ÿæ ⁄©€å ÿ®ÿßÿ™ ÿ≥ŸÜŸÜ€í ÿßŸàÿ± ŸÖÿØÿØ ⁄©ÿ±ŸÜ€í ⁄©€í ŸÑ€å€í €ÅŸà⁄∫€î ÿ¢Ÿæ ⁄©€åÿ≥ÿß ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫ÿü'
    : 'I\'m here to listen and support you. How are you feeling right now?';
}

// Phase 3: Emotional Support Response Generation
function generateEmotionalSupportResponse(
  text: string, 
  emotion: string, 
  confidence: number, 
  language: string = 'en'
): string {
  const responses = {
    en: {
      stress: [
        "I can sense you're feeling overwhelmed. Let's take this one step at a time. What's been weighing on your mind?",
        "Stress can feel overwhelming, but you're not alone. Would you like to talk about what's causing this pressure?",
        "I notice you might be feeling stressed. Taking deep breaths can help. What's been on your mind lately?"
      ],
      sadness: [
        "I can hear that you're going through a difficult time. Your feelings are valid, and I'm here to listen.",
        "It sounds like you're feeling sad. That's completely okay - would you like to share what's been bothering you?",
        "I sense some sadness in what you're sharing. Sometimes talking helps - I'm here for you."
      ],
      anger: [
        "I can feel your frustration. It's okay to feel angry - these emotions are valid. What's been upsetting you?",
        "It sounds like something has really bothered you. Would you like to talk about what's making you feel this way?",
        "I sense some anger in your message. Let's work through this together - what happened?"
      ],
      fear: [
        "I can sense some worry or fear in what you're sharing. It's brave of you to reach out. What's been frightening you?",
        "Fear can be overwhelming, but you're safe here. Would you like to talk about what's been making you anxious?",
        "I notice you might be feeling scared. That's completely understandable - what's been on your mind?"
      ],
      joy: [
        "I can hear the positivity in your message! It's wonderful that you're feeling good. What's been making you happy?",
        "It sounds like you're in a good mood - that's great to hear! Would you like to share what's been going well?",
        "I sense some happiness in what you're sharing. It's lovely to hear from someone feeling positive!"
      ],
      neutral: [
        "Thank you for reaching out. I'm here to listen and support you. How are you feeling right now?",
        "I'm glad you're here. Sometimes it helps just to talk. What's been on your mind?",
        "I'm here for you. Would you like to share what brought you here today?"
      ]
    },
    ur: {
      stress: [
        "ŸÖÿ¨⁄æ€í ŸÑ⁄Ø ÿ±€Åÿß €Å€í ÿ¢Ÿæ Ÿæÿ±€åÿ¥ÿßŸÜ €Å€å⁄∫€î ÿ¢ÿ¶€å€í ÿßÿ≥€í ÿ¢€Åÿ≥ÿ™€Å ÿ¢€Åÿ≥ÿ™€Å ÿ≠ŸÑ ⁄©ÿ±ÿ™€í €Å€å⁄∫€î ⁄©€åÿß ÿ®ÿßÿ™ ÿ¢Ÿæ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ± ÿ±€Å€å €Å€íÿü",
        "ÿ™ŸÜÿßÿ§ ŸÖÿ¥⁄©ŸÑ €ÅŸà ÿ≥⁄©ÿ™ÿß €Å€íÿå ŸÑ€å⁄©ŸÜ ÿ¢Ÿæ ÿß⁄©€åŸÑ€í ŸÜ€Å€å⁄∫ €Å€å⁄∫€î ⁄©€åÿß ÿ¢Ÿæ ÿ®ÿ™ÿßŸÜÿß ⁄Üÿß€Å€å⁄∫ ⁄Ø€í ⁄©€Å ⁄©€åÿß ÿ¢Ÿæ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ± ÿ±€Åÿß €Å€íÿü"
      ],
      sadness: [
        "ŸÖÿ¨⁄æ€í ŸÑ⁄Ø ÿ±€Åÿß €Å€í ÿ¢Ÿæ ŸÖÿ¥⁄©ŸÑ ŸàŸÇÿ™ ÿ≥€í ⁄Øÿ≤ÿ± ÿ±€Å€í €Å€å⁄∫€î ÿ¢Ÿæ ⁄©€í ÿßÿ≠ÿ≥ÿßÿ≥ÿßÿ™ ÿØÿ±ÿ≥ÿ™ €Å€å⁄∫ÿå ÿßŸàÿ± ŸÖ€å⁄∫ €å€Åÿß⁄∫ ÿ≥ŸÜŸÜ€í ⁄©€í ŸÑ€å€í €ÅŸà⁄∫€î",
        "ŸÑ⁄Ø ÿ±€Åÿß €Å€í ÿ¢Ÿæ ÿßÿØÿßÿ≥ €Å€å⁄∫€î €å€Å ÿ®ÿßŸÑ⁄©ŸÑ Ÿπ⁄æ€å⁄© €Å€í - ⁄©€åÿß ÿ¢Ÿæ ÿ®ÿ™ÿßŸÜÿß ⁄Üÿß€Å€å⁄∫ ⁄Ø€í ⁄©€Å ⁄©€åÿß ÿ¢Ÿæ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ± ÿ±€Åÿß €Å€íÿü"
      ],
      neutral: [
        "ÿ¢Ÿæ ⁄©ÿß €å€Åÿß⁄∫ ÿ¢ŸÜ€í ⁄©ÿß ÿ¥⁄©ÿ±€å€Å€î ŸÖ€å⁄∫ €å€Åÿß⁄∫ ÿ¢Ÿæ ⁄©€å ÿ®ÿßÿ™ ÿ≥ŸÜŸÜ€í ÿßŸàÿ± ŸÖÿØÿØ ⁄©ÿ±ŸÜ€í ⁄©€í ŸÑ€å€í €ÅŸà⁄∫€î ÿ¢Ÿæ ⁄©€åÿ≥ÿß ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫ÿü",
        "ŸÖ€å⁄∫ ÿÆŸàÿ¥ €ÅŸà⁄∫ ⁄©€Å ÿ¢Ÿæ €å€Åÿß⁄∫ €Å€å⁄∫€î ⁄©ÿ®⁄æ€å ⁄©ÿ®⁄æ€å ÿ®ÿßÿ™ ⁄©ÿ±ŸÜÿß ŸÖÿØÿØ ⁄©ÿ±ÿ™ÿß €Å€í€î ÿ¢Ÿæ ⁄©€í ÿØŸÑ ŸÖ€å⁄∫ ⁄©€åÿß ÿ®ÿßÿ™ €Å€íÿü"
      ]
    }
  };

  const emotionResponses = responses[language as keyof typeof responses] || responses.en;
  const responseArray = emotionResponses[emotion as keyof typeof emotionResponses] || emotionResponses.neutral;
  
  // Select response based on confidence level
  let responseIndex = 0;
  if (confidence > 0.8) {
    responseIndex = 0; // Most confident response
  } else if (confidence > 0.6) {
    responseIndex = Math.min(1, responseArray.length - 1);
  } else {
    responseIndex = Math.min(2, responseArray.length - 1);
  }
  
  return responseArray[responseIndex] || responseArray[0];
}

export async function registerRoutes(app: Express): Promise<Server> {
  // Auth middleware
  await setupAuth(app);
  
  // Add token extraction middleware for all routes
  app.use(extractTokenFromHeader);

  // Auth routes
  app.get('/api/auth/user', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      // For local development
      if (process.env.NODE_ENV === 'development') {
        const mockUser = {
          id: 'local-user-123',
          email: 'developer@local.dev',
          firstName: 'Local',
          lastName: 'Developer',
          profileImageUrl: 'https://via.placeholder.com/150',
          userType: 'adult', // Can be 'adult', 'child', or 'guardian'
          language: 'english',
          createdAt: new Date(),
          updatedAt: new Date(),
        };
        
        // Try to get from database first, if that fails use mock user
        try {
          const userId = req.user?.claims?.sub || req.user?.id;
          if (userId) {
            const user = await mongoStorage.getUser(userId);
            if (user) {
              return res.json(user);
            }
          }
          
          console.log('Using mock user for development');
          return res.json(mockUser);
        } catch (error) {
          console.log('Database not available, returning mock user');
          return res.json(mockUser);
        }
      }
      
      // Production flow
      try {
        const userId = req.user?.claims?.sub || req.user?.id;
        if (!userId) {
          return res.status(401).json({ message: "User ID not found in session" });
        }
        
        const user = await mongoStorage.getUser(userId);
        if (!user) {
          return res.status(404).json({ message: "User not found in database" });
        }
        
        res.json(user);
      } catch (error) {
        console.error("Error fetching user:", error);
        res.status(500).json({ message: "Failed to fetch user" });
      }
    } catch (error) {
      console.error("Error in auth route:", error);
      res.status(500).json({ message: "Internal server error" });
    }
  });
  
  // Authentication endpoints (available in all environments)
  if (mongoStorage) {
    // User login endpoint
    app.post('/api/auth/login', async (req: AuthenticatedRequest, res: Response) => {
      try {
        const { email, password } = req.body;
        
        if (!email || !password) {
          return res.status(400).json({ message: "Email and password are required" });
        }
        
        // Authenticate user
        const user = await AuthService.login({ email, password });
        
        // Set user in session
        if (req.session) {
          req.session.user = {
            id: user.id,
            claims: { sub: user.id }
          };
          console.log('User logged in via session:', user.id, user.userType);
        }
        
        // Return user with auth token (user ID can serve as token)
        res.json({ success: true, user, authToken: user.id });
      } catch (error: any) {
        console.error("Login error:", error.message);
        res.status(401).json({ message: error.message });
      }
    });
    
    // User signup endpoint
    app.post('/api/auth/signup', async (req: AuthenticatedRequest, res: Response) => {
      try {
        console.log('Signup request received:', req.body);
        const { firstName, lastName, email, password, userType, language } = req.body;
        
        if (!firstName || !lastName || !email || !password || !userType || !language) {
          console.log('Missing required fields');
          return res.status(400).json({ success: false, message: "All fields are required" });
        }
        
        // Create new user
        console.log('Creating user with AuthService...');
        const user = await AuthService.signup({
          firstName,
          lastName,
          email,
          password,
          userType,
          language
        });
        
        console.log('User created successfully:', user.id, user.userType);
        
        // Set user in session
        if (req.session) {
          req.session.user = {
            id: user.id,
            claims: { sub: user.id }
          };
          console.log('Session set for user:', user.id);
        }
        
        console.log('Sending success response');
        // Return user with auth token (user ID can serve as token)
        res.json({ success: true, user, authToken: user.id });
      } catch (error: any) {
        console.error("Signup error:", error.message);
        res.status(400).json({ success: false, message: error.message });
      }
    });
    
    // Session information endpoint
    app.get('/api/auth/session', (req: AuthenticatedRequest, res: Response) => {
      res.json({
        session: req.session,
        user: req.user,
        isAuthenticated: req.isAuthenticated ? req.isAuthenticated() : false
      });
    });
    
    // Logout endpoint
    app.get('/api/logout', (req: AuthenticatedRequest, res: Response) => {
      if (req.session) {
        req.session.destroy((err: any) => {
          if (err) {
            console.error('Session destruction error:', err);
          }
        });
      }
      res.json({ success: true, message: 'Logged out successfully' });
    });
  }

  // Speech therapy routes
  app.post('/api/speech/session', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const userId = req.user?.claims?.sub;
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }
      
      const { sessionType } = req.body;
      
      const session = await mongoStorage.createSpeechSession({ userId, sessionType });
      res.json(session);
    } catch (error) {
      console.error("Error creating speech session:", error);
      res.status(500).json({ message: "Failed to create session" });
    }
  });

  app.post('/api/speech/record', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { sessionId, word, phonetic, userTranscription, language, userAudio } = req.body;
      
      const result = await SpeechService.recordSpeechAttempt(
        sessionId,
        word,
        phonetic || '',
        userTranscription,
        language,
        userAudio
      );
      
      res.json(result);
    } catch (error) {
      console.error("Error recording speech attempt:", error);
      res.status(500).json({ message: "Failed to record speech attempt" });
    }
  });

  app.post('/api/speech/assessment', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const userId = req.user?.claims?.sub;
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }
      
      const { assessmentResults } = req.body;
      
      const result = await SpeechService.conductAssessment(userId, assessmentResults);
      res.json(result);
    } catch (error) {
      console.error("Error conducting assessment:", error);
      res.status(500).json({ message: "Failed to conduct assessment" });
    }
  });

  app.get('/api/speech/progress', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const userId = req.user?.claims?.sub;
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }
      
      const progress = await SpeechService.getUserProgress(userId);
      res.json(progress);
    } catch (error) {
      console.error("Error fetching progress:", error);
      res.status(500).json({ message: "Failed to fetch progress" });
    }
  });

  // Emotional support routes
  app.post('/api/chat/session', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const userId = req.user?.claims?.sub;
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }
      
      const session = await mongoStorage.createEmotionalSession({ 
        userId, 
        sessionType: 'chat' 
      });
      res.json(session);
    } catch (error) {
      console.error("Error creating chat session:", error);
      res.status(500).json({ message: "Failed to create chat session" });
    }
  });

  app.post('/api/chat/message', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { sessionId, message, voiceTone } = req.body;
      
      // Analyze emotion and generate AI response
      const emotionAnalysis = await analyzeEmotion(message, voiceTone);
      
      // Save user message
      await mongoStorage.addMessageToEmotionalSession(sessionId, {
        role: 'user',
        content: message
      });
      
      // Save AI response
      await mongoStorage.addMessageToEmotionalSession(sessionId, {
        role: 'assistant',
        content: emotionAnalysis.response || 'I understand you might be going through something difficult. Would you like to talk about it?'
      });
      
      res.json({
        response: emotionAnalysis.response,
        emotion: emotionAnalysis.emotion,
        confidence: emotionAnalysis.confidence,
      });
    } catch (error) {
      console.error("Error processing chat message:", error);
      res.status(500).json({ message: "Failed to process message" });
    }
  });

  app.get('/api/chat/messages/:sessionId', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { sessionId } = req.params;
      const userId = req.user?.claims?.sub;
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }
      
      const session = await mongoStorage.getEmotionalSessions(userId, 1);
      const messages = session.length > 0 ? session[0].messages : [];
      res.json(messages); // Return in chronological order
    } catch (error) {
      console.error("Error fetching chat messages:", error);
      res.status(500).json({ message: "Failed to fetch messages" });
    }
  });

  // NEW: Superior Therapeutic Chat Endpoint with Advanced Quality Metrics
  app.post('/api/chat/therapeutic-superior', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { sessionId, message, emotions = [], context = [], language = 'en', sessionContext = {} } = req.body;
      const userId = req.user?.claims?.sub;
      
      if (!userId) {
        return res.status(401).json({ message: "User not authenticated" });
      }

      if (!message || !sessionId) {
        return res.status(400).json({ message: "Message and sessionId are required" });
      }

      console.log('[Superior Therapeutic API] Processing request for user:', userId);
      console.log('[Superior Therapeutic API] Message:', message);
      console.log('[Superior Therapeutic API] Emotions detected:', emotions);

      // Generate superior therapeutic response with quality metrics
      const therapeuticResult = await generateSuperiorTherapeuticResponse(
        message,
        context,
        emotions,
        sessionContext,
        userId
      );

      // Save user message to session
      await mongoStorage.addMessageToEmotionalSession(sessionId, {
        role: 'user',
        content: message,
        emotions: emotions,
        timestamp: new Date().toISOString(),
        language: language
      } as any);

      // Save AI response with quality metrics
      await mongoStorage.addMessageToEmotionalSession(sessionId, {
        role: 'assistant',
        content: therapeuticResult.response,
        model_used: therapeuticResult.model_used,
        quality: therapeuticResult.quality,
        confidence: therapeuticResult.confidence,
        empathy_score: therapeuticResult.empathy_score,
        therapeutic_level: therapeuticResult.therapeutic_level,
        emotion_alignment: therapeuticResult.emotion_alignment,
        context_relevance: therapeuticResult.context_relevance,
        fallback_used: therapeuticResult.fallback_used,
        session_insights: therapeuticResult.session_insights,
        timestamp: therapeuticResult.timestamp
      } as any);

      console.log('[Superior Therapeutic API] Response generated with quality:', therapeuticResult.quality);
      console.log('[Superior Therapeutic API] Empathy score:', therapeuticResult.empathy_score);

      // Return comprehensive response with quality indicators
      res.json({
        response: therapeuticResult.response,
        quality_metrics: {
          overall_quality: therapeuticResult.quality,
          confidence: therapeuticResult.confidence,
          empathy_score: therapeuticResult.empathy_score,
          therapeutic_level: therapeuticResult.therapeutic_level,
          emotion_alignment: therapeuticResult.emotion_alignment,
          context_relevance: therapeuticResult.context_relevance
        },
        model_info: {
          model_used: therapeuticResult.model_used,
          fallback_used: therapeuticResult.fallback_used,
          timestamp: therapeuticResult.timestamp
        },
        session_insights: therapeuticResult.session_insights,
        status: 'success'
      });

    } catch (error) {
      console.error('[Superior Therapeutic API] Error:', error);
      res.status(500).json({ 
        message: "Failed to generate superior therapeutic response",
        error: error instanceof Error ? error.message : 'Unknown error',
        status: 'error'
      });
    }
  });

  // Temporary test endpoint for Phase 1 testing (no auth required)
  app.post('/api/test-emotional-support', async (req: Request, res: Response) => {
    try {
      const { audio, text, language } = req.body;
      let inputText = text;

      if (audio) {
        try {
          const audioBuffer = Buffer.from(audio, 'base64');
          const whisperLanguage = language?.startsWith('ur') ? 'ur' : 'en';
          inputText = await transcribeAudio(audioBuffer, whisperLanguage);
        } catch (sttError) {
          console.warn('STT failed, using text input:', sttError);
          inputText = text || 'Could not transcribe audio';
        }
      }

      if (!inputText) {
        return res.status(400).json({ error: 'No input provided' });
      }

      // Phase 3: Use the new emotion detection system
      const emotionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
      const emotion = await detectEmotionFromText(inputText, emotionLanguage);
      
      // Phase 4: Generate personalized response based on detected emotion
      let response = `I understand you're feeling ${emotion.emotion}. That's completely valid. Would you like to tell me more about what's making you feel this way?`;
      
      try {
        response = await generateEmotionalResponse(emotion.emotion, inputText, emotionLanguage);
        console.log('Phase 4: Generated personalized response for test endpoint');
      } catch (error) {
        console.log('Phase 4: Using fallback response for test endpoint');
      }
      
      res.json({ 
        transcription: inputText, 
        emotion, 
        response: response,
        detectedEmotion: emotion.emotion,
        confidence: emotion.confidence
      });
    } catch (error) {
      console.error("Error processing test emotional support request:", error);
      res.status(500).json({ 
        error: 'Processing failed',
        details: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  });

  // Test endpoint for Urdu text transmission
  app.post('/api/test-urdu', async (req: Request, res: Response) => {
    try {
      const { text } = req.body;
      console.log('\n=== URDU TEST ENDPOINT ===');
      console.log('Received text:', text);
      console.log('Text length:', text ? text.length : 0);
      console.log('Has Urdu regex test:', text ? /[\u0600-\u06FF\u0750-\u077F]/.test(text) : false);
      console.log('Contains Ÿæÿ±€åÿ¥ÿßŸÜ:', text ? text.includes('Ÿæÿ±€åÿ¥ÿßŸÜ') : false);
      console.log('Contains ÿßÿØÿßÿ≥:', text ? text.includes('ÿßÿØÿßÿ≥') : false);
      console.log('Character codes:', text ? [...text].map(c => c.charCodeAt(0)).slice(0, 10) : []);
      
      res.json({
        received: text,
        length: text ? text.length : 0,
        hasUrdu: text ? /[\u0600-\u06FF\u0750-\u077F]/.test(text) : false,
        keywords: {
          pareshan: text ? text.includes('Ÿæÿ±€åÿ¥ÿßŸÜ') : false,
          udas: text ? text.includes('ÿßÿØÿßÿ≥') : false
        }
      });
    } catch (error) {
      console.error('Test endpoint error:', error);
      res.status(500).json({ error: error instanceof Error ? error.message : 'Unknown error occurred' });
    }
  });

  // Test endpoint for chat mode (no auth required)
  app.post('/api/test-chat', async (req: Request, res: Response) => {
    try {
      const { message, sessionId, language } = req.body;
      
      console.log('\n=== CHAT MODE TEST ===');
      console.log('Received message:', message);
      console.log('Message length:', message ? message.length : 0);
      console.log('Session ID:', sessionId);
      console.log('Language:', language || 'en');
      
      // Validate input
      if (!message || message.trim().length === 0) {
        return res.status(400).json({ 
          error: 'No message provided',
          received: message 
        });
      }
      
      // Process text input (no STT needed for chat mode)
      const processedMessage = message.trim();
      
      // Phase 3: Use OPTIMIZED emotion detection for chat mode
      console.log('‚ö° Chat Mode: Running optimized emotion detection...');
      console.log('üìù Processing message:', processedMessage);
      console.log('üåê Language:', language || 'en');
      
      let detectedEmotion = 'neutral';
      let confidence = 0;
      let emotionMethod = 'fallback';
      
      try {
        console.log('üîÑ Calling detectEmotionFromText...');
        // Set a shorter timeout for chat mode to avoid hanging
        const emotionPromise = detectEmotionFromText(processedMessage, language || 'en');
        const timeoutPromise = new Promise((_, reject) => 
          setTimeout(() => reject(new Error('Chat mode timeout (18s)')), 18000)
        );
        
        const emotionResult = await Promise.race([emotionPromise, timeoutPromise]) as any;
        console.log('üìä Emotion result received:', emotionResult);
        
        if (emotionResult && typeof emotionResult === 'object') {
          detectedEmotion = emotionResult.emotion || 'neutral';
          confidence = emotionResult.confidence || 0.5;
          emotionMethod = 'optimized';
          console.log(`‚úÖ Chat Mode Emotion: ${detectedEmotion} (${confidence.toFixed(3)})`);
        } else {
          throw new Error('Invalid emotion result format');
        }
      } catch (error: any) {
        console.log('‚ö†Ô∏è  Optimized detection failed, using fallback keyword detection');
        console.log('‚ùå Error details:', error?.message || 'Unknown error');
        
        
        // Fallback to enhanced keyword detection with raw emotion labels
        const lowerMessage = processedMessage.toLowerCase();
        
        // More specific emotion detection
        if (lowerMessage.includes('disappoint') || lowerMessage.includes('let down')) {
          detectedEmotion = 'disappointment';
          confidence = 0.6;
        } else if (lowerMessage.includes('grateful') || lowerMessage.includes('thankful')) {
          detectedEmotion = 'gratitude';
          confidence = 0.6;
        } else if (lowerMessage.includes('annoyed') || lowerMessage.includes('irritated')) {
          detectedEmotion = 'annoyance';
          confidence = 0.6;
        } else if (lowerMessage.includes('excited') || lowerMessage.includes('thrilled')) {
          detectedEmotion = 'excitement';
          confidence = 0.6;
        } else if (lowerMessage.includes('nervous') || lowerMessage.includes('worried')) {
          detectedEmotion = 'nervousness';
          confidence = 0.6;
        } else if (lowerMessage.includes('embarrassed') || lowerMessage.includes('ashamed')) {
          detectedEmotion = 'embarrassment';
          confidence = 0.6;
        } else if (lowerMessage.includes('curious') || lowerMessage.includes('wonder')) {
          detectedEmotion = 'curiosity';
          confidence = 0.6;
        } else if (lowerMessage.includes('approve') || lowerMessage.includes('agree')) {
          detectedEmotion = 'approval';
          confidence = 0.6;
        } else if (lowerMessage.includes('caring') || lowerMessage.includes('concern')) {
          detectedEmotion = 'caring';
          confidence = 0.6;
        } else if (lowerMessage.includes('relief') || lowerMessage.includes('relieved')) {
          detectedEmotion = 'relief';
          confidence = 0.6;
        } else if (lowerMessage.includes('sad') || lowerMessage.includes('upset') || lowerMessage.includes('depressed') || lowerMessage.includes('hopeless')) {
          detectedEmotion = 'sadness';
          confidence = 0.6;
        } else if (lowerMessage.includes('angry') || lowerMessage.includes('mad') || lowerMessage.includes('frustrated')) {
          detectedEmotion = 'anger';
          confidence = 0.6;
        } else if (lowerMessage.includes('anxious') || lowerMessage.includes('anxiety') || lowerMessage.includes('fear')) {
          detectedEmotion = 'anxiety';
          confidence = 0.6;
        } else if (lowerMessage.includes('happy') || lowerMessage.includes('joy')) {
          detectedEmotion = 'joy';
          confidence = 0.6;
        }
        emotionMethod = 'keyword-fallback';
        console.log(`üîÑ Fallback emotion: ${detectedEmotion} (confidence: ${confidence})`);
      }
      
      // **UPDATED**: Use Superior Therapeutic Model for response generation
      console.log('üß† Generating response using Superior Therapeutic Model...');
      
      let chatResponse = '';
      let qualityMetrics = {};
      let modelInfo = {};
      let sessionInsights = {};
      
      try {
        // Generate superior therapeutic response
        const therapeuticResult = await generateSuperiorTherapeuticResponse(
          processedMessage,
          [], // context (empty for new sessions)
          [detectedEmotion], // emotions detected
          { sessionId: sessionId || 'test-session', mode: 'chat-text' },
          'test-user'
        );
        
        chatResponse = therapeuticResult.response;
        qualityMetrics = {
          overall_quality: therapeuticResult.quality,
          confidence: therapeuticResult.confidence,
          empathy_score: therapeuticResult.empathy_score,
          therapeutic_level: therapeuticResult.therapeutic_level,
          emotion_alignment: therapeuticResult.emotion_alignment,
          context_relevance: therapeuticResult.context_relevance
        };
        modelInfo = {
          model_used: therapeuticResult.model_used,
          fallback_used: therapeuticResult.fallback_used,
          timestamp: therapeuticResult.timestamp
        };
        sessionInsights = therapeuticResult.session_insights;
        
        console.log('‚úÖ Superior therapeutic response generated successfully');
        console.log('üéØ Quality score:', therapeuticResult.quality);
        console.log('‚ù§Ô∏è Empathy score:', therapeuticResult.empathy_score);
        
      } catch (error) {
        console.error('‚ùå Superior therapeutic model failed, using fallback:', error);
        
        // Fallback to basic emotion-based responses (original logic)
        switch (detectedEmotion) {
          case 'stress':
          case 'anxiety':
          case 'nervousness':
            chatResponse = "I can sense you might be feeling stressed or anxious. That's completely understandable. Take a deep breath with me. What's been weighing on your mind?";
            break;
          case 'sadness':
          case 'disappointment':
          case 'grief':
            chatResponse = "I hear that you're going through a difficult time. It's okay to feel sad or disappointed sometimes. Would you like to share what's been troubling you?";
            break;
          case 'anger':
          case 'annoyance':
          case 'frustration':
            chatResponse = "I understand you're feeling frustrated or angry. Those feelings are completely valid. What's been causing these intense feelings?";
            break;
          default:
            chatResponse = "Thank you for sharing that with me. I'm here to listen and support you. How are you feeling right now?";
        }
        
        modelInfo = { model_used: 'basic-fallback', fallback_used: true };
      }
      
      // Return enhanced chat response with therapeutic model data
      res.json({
        success: true,
        userMessage: processedMessage,
        detectedEmotion: detectedEmotion,
        confidence: confidence,
        chatResponse: chatResponse,
        
        // **NEW**: Superior therapeutic model information
        quality_metrics: qualityMetrics,
        model_info: modelInfo,
        session_insights: sessionInsights,
        
        // Original fields
        timestamp: new Date().toISOString(),
        sessionId: sessionId || 'test-session',
        language: language || 'en',
        mode: 'chat-text-therapeutic', // Updated mode name
        sttUsed: false,
        emotionMethod: emotionMethod
      });
      
    } catch (error) {
      console.error('Chat test endpoint error:', error);
      res.status(500).json({ 
        error: error instanceof Error ? error.message : 'Unknown error occurred',
        mode: 'chat-text'
      });
    }
  });

  // Test endpoint for Superior Therapeutic Model (no auth required)
  app.post('/api/test-superior-therapeutic', async (req: Request, res: Response) => {
    try {
      const { message, emotions = [], context = [], language = 'en', sessionContext = {} } = req.body;
      
      console.log('\n=== SUPERIOR THERAPEUTIC TEST ===');
      console.log('Received message:', message);
      console.log('Emotions:', emotions);
      console.log('Context length:', context.length);
      console.log('Language:', language);
      
      // Validate input
      if (!message || message.trim().length === 0) {
        return res.status(400).json({ 
          error: 'No message provided',
          received: message 
        });
      }

      // Generate superior therapeutic response
      const therapeuticResult = await generateSuperiorTherapeuticResponse(
        message,
        context,
        emotions,
        sessionContext,
        'test-user'
      );

      console.log('‚úÖ Superior therapeutic response generated');
      console.log('Response preview:', therapeuticResult.response.substring(0, 100) + '...');
      console.log('Quality metrics:', {
        quality: therapeuticResult.quality,
        empathy_score: therapeuticResult.empathy_score,
        therapeutic_level: therapeuticResult.therapeutic_level
      });

      // Return comprehensive test response
      res.json({
        message: 'Superior therapeutic response generated successfully',
        response: therapeuticResult.response,
        quality_metrics: {
          overall_quality: therapeuticResult.quality,
          confidence: therapeuticResult.confidence,
          empathy_score: therapeuticResult.empathy_score,
          therapeutic_level: therapeuticResult.therapeutic_level,
          emotion_alignment: therapeuticResult.emotion_alignment,
          context_relevance: therapeuticResult.context_relevance
        },
        model_info: {
          model_used: therapeuticResult.model_used,
          fallback_used: therapeuticResult.fallback_used,
          timestamp: therapeuticResult.timestamp
        },
        session_insights: therapeuticResult.session_insights,
        test_info: {
          endpoint: 'test-superior-therapeutic',
          input_message_length: message.length,
          emotions_detected: emotions,
          context_items: context.length,
          language: language
        },
        status: 'success'
      });

    } catch (error) {
      console.error('Superior therapeutic test endpoint error:', error);
      res.status(500).json({ 
        error: error instanceof Error ? error.message : 'Unknown error occurred',
        mode: 'superior-therapeutic-test',
        details: {
          stack: error instanceof Error ? error.stack : undefined,
          message: error instanceof Error ? error.message : 'Unknown error'
        }
      });
    }
  });

  // Enhanced Emotional Support Endpoint with Advanced Conversational Therapy AI
  app.post('/api/emotional-support-enhanced', upload.single('audio'), async (req: Request, res: Response) => {
    try {
      const { 
        mode, 
        language, 
        history, 
        sessionId, 
        userContext,
        enableAvatar = true,
        enableTTS = true 
      } = req.body;
      
      let text = req.body.text;
      let audioPath: string | null = null;
      
      console.log('üß† Enhanced Therapy AI: Processing request');
      console.log('üìä Mode:', mode, 'Language:', language, 'Avatar:', enableAvatar);

      // Handle voice mode with advanced audio processing
      if (mode === 'voice' && req.file) {
        try {
          console.log('üéôÔ∏è Processing audio file:', req.file.size, 'bytes');
          const audioBuffer = req.file.buffer;
          
          if (!validateAudioBuffer(audioBuffer)) {
            throw new Error('Invalid audio file format or size');
          }
          
          // Save audio for emotion analysis
          const tempDir = path.join(process.cwd(), 'temp');
          if (!fs.existsSync(tempDir)) {
            fs.mkdirSync(tempDir, { recursive: true });
          }
          audioPath = path.join(tempDir, `audio_${Date.now()}.wav`);
          fs.writeFileSync(audioPath, audioBuffer);
          
          const whisperLanguage = language?.startsWith('ur') ? 'ur' : 'en';
          
          try {
            text = await transcribeAudio(audioBuffer, whisperLanguage);
            console.log('‚úÖ Speech-to-text successful:', text?.length, 'characters');
          } catch (sttError) {
            console.warn('‚ö†Ô∏è Primary STT failed, using fallback:', sttError);
            text = await simpleTranscribeAudio(audioBuffer, whisperLanguage);
          }
        } catch (audioError) {
          console.warn('‚ùå Audio processing failed:', audioError);
          text = req.body.text || 'Voice input received but processing failed';
        }
      }

      // Ensure we have text to work with
      if (!text || text.trim().length === 0) {
        text = mode === 'voice' 
          ? 'I received your voice message and I\'m here to listen.' 
          : 'Hello, I\'m here to support you. How are you feeling today?';
      }

      console.log('üìù Processed text:', text.substring(0, 100) + '...');

      // Enhanced emotion detection with therapeutic context
      let emotionResult;
      const detectionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
      
      if (mode === 'voice' && audioPath && fs.existsSync(audioPath)) {
        console.log('üéØ Running combined emotion detection (text + voice)...');
        try {
          const combinedResult = await detectCombinedEmotion(text, audioPath, detectionLanguage);
          emotionResult = {
            emotion: combinedResult.combined.emotion,
            confidence: combinedResult.combined.confidence,
            textEmotion: combinedResult.text.emotion,
            voiceEmotion: combinedResult.voice.emotion,
            method: 'combined',
            rawData: combinedResult
          };
        } catch (emotionError) {
          console.warn('‚ö†Ô∏è Combined emotion detection failed, using text-only:', emotionError);
          const textResult = await detectEmotionFromText(text, detectionLanguage);
          emotionResult = {
            emotion: textResult.emotion,
            confidence: textResult.confidence,
            method: 'text-fallback'
          };
        }
        
        // Clean up temp audio file
        try {
          fs.unlinkSync(audioPath);
        } catch (cleanupError) {
          console.warn('‚ö†Ô∏è Failed to clean up temp audio file:', cleanupError);
        }
      } else {
        console.log('üìä Running text emotion detection...');
        const textResult = await detectEmotionFromText(text, detectionLanguage);
        emotionResult = {
          emotion: textResult.emotion,
          confidence: textResult.confidence,
          method: 'text-only'
        };
      }

      console.log('üé≠ Emotion detected:', emotionResult.emotion, 'confidence:', emotionResult.confidence);

      // Parse conversation history for context
      let conversationHistory: ConversationHistory[] = [];
      try {
        if (history) {
          const parsedHistory = typeof history === 'string' ? JSON.parse(history) : history;
          conversationHistory = Array.isArray(parsedHistory) ? parsedHistory.slice(-10) : []; // Keep last 10 exchanges
          console.log('üí≠ Conversation history loaded:', conversationHistory.length, 'items');
        }
      } catch (historyError) {
        console.warn('‚ö†Ô∏è Failed to parse conversation history:', historyError);
        conversationHistory = [];
      }

      // Parse user context
      let parsedUserContext = {};
      try {
        if (userContext) {
          parsedUserContext = typeof userContext === 'string' ? JSON.parse(userContext) : userContext;
        }
      } catch (contextError) {
        console.warn('‚ö†Ô∏è Failed to parse user context:', contextError);
      }

      // Create enhanced request
      const enhancedRequest: EnhancedResponseRequest = {
        text,
        emotion: emotionResult.emotion,
        language: detectionLanguage,
        history: conversationHistory,
        userContext: parsedUserContext,
        sessionContext: {
          sessionId: sessionId || `session_${Date.now()}`,
          sessionStart: Date.now(),
          mode: mode || 'text',
          avatar: enableAvatar
        }
      };

      // Generate enhanced therapeutic response
      try {
        console.log('üöÄ Generating enhanced therapeutic response...');
        const responseResult: EnhancedResponseResult = await generateEnhancedConversationalResponse(enhancedRequest);
        
        console.log('‚úÖ Enhanced response generated successfully');
        console.log('üéµ TTS available:', !!responseResult.audioBase64);
        console.log('üß† Therapeutic techniques:', responseResult.therapeuticTechniques?.join(', '));

        // Prepare response with all enhanced features
        const fullResponse = {
          // Core response data
          transcription: text,
          response: responseResult.response,
          emotion: responseResult.emotion,
          confidence: responseResult.confidence,
          
          // Enhanced features
          contextAnalysis: responseResult.contextAnalysis,
          therapeuticTechniques: responseResult.therapeuticTechniques,
          conversationFlow: responseResult.conversationFlow,
          
          // Audio/Avatar support
          audioBase64: enableTTS ? responseResult.audioBase64 : undefined,
          avatarSupported: enableAvatar,
          
          // Metadata
          mode: mode || 'text',
          language: detectionLanguage,
          sessionId: enhancedRequest.sessionContext?.sessionId,
          emotionDetails: emotionResult,
          
          // Processing information
          processingTime: responseResult.metadata?.processingTime,
          model: responseResult.metadata?.model,
          features: responseResult.metadata?.features,
          historyLength: conversationHistory.length,
          
          // Success indicators
          enhanced: true,
          conversational: true,
          therapeutic: true
        };

        res.json(fullResponse);

      } catch (enhancedError) {
        console.warn('‚ùå Enhanced response failed, using intelligent fallback:', enhancedError);
        
        // Intelligent fallback with therapeutic principles
        const fallbackResponse = generateIntelligentTherapeuticFallback(
          text, 
          emotionResult.emotion, 
          detectionLanguage,
          conversationHistory
        );

        res.json({
          transcription: text,
          response: fallbackResponse.response,
          emotion: emotionResult.emotion,
          confidence: emotionResult.confidence,
          mode: mode || 'text',
          language: detectionLanguage,
          emotionDetails: emotionResult,
          therapeuticTechniques: fallbackResponse.techniques,
          enhanced: false,
          conversational: true,
          therapeutic: true,
          fallbackUsed: true,
          fallbackReason: enhancedError instanceof Error ? enhancedError.message : 'Enhanced processing failed'
        });
      }

    } catch (error) {
      console.error("‚ùå Enhanced emotional support processing failed:", error);
      res.status(500).json({ 
        error: 'Enhanced processing failed',
        details: error instanceof Error ? error.message : 'Unknown error',
        fallback: generateBasicTherapeuticResponse('en') // Always provide some therapeutic response
      });
    }
  });

  // Simple emotional support endpoint without authentication
  app.post('/api/emotional-support', upload.single('audio'), async (req: Request, res: Response) => {
    try {
      const { mode, language, history } = req.body;
      let text = req.body.text;
      let audioPath: string | null = null;

      console.log('Processing emotional support request - Mode:', mode, 'Language:', language);

      // Phase 3: Handle voice mode with audio file processing
      if (mode === 'voice' && req.file) {
        try {
          console.log('Processing audio file, size:', req.file.size, 'bytes');
          const audioBuffer = req.file.buffer;
          
          // Validate audio buffer first
          if (!validateAudioBuffer(audioBuffer)) {
            throw new Error('Invalid audio file format or size');
          }
          
          // Save audio to temp file for emotion detection
          const tempDir = path.join(process.cwd(), 'temp');
          if (!fs.existsSync(tempDir)) {
            fs.mkdirSync(tempDir, { recursive: true });
          }
          audioPath = path.join(tempDir, `audio_${Date.now()}.wav`);
          fs.writeFileSync(audioPath, audioBuffer);
          
          const whisperLanguage = language?.startsWith('ur') ? 'ur' : 'en';
          
          try {
            // Try the full Whisper transcription first
            text = await transcribeAudio(audioBuffer, whisperLanguage);
            console.log('Whisper transcription successful:', text?.length, 'characters');
          } catch (whisperError) {
            console.warn('Whisper failed, using simple fallback:', whisperError);
            // Fallback to simple transcription
            text = await simpleTranscribeAudio(audioBuffer, whisperLanguage);
            console.log('Fallback transcription used');
          }
        } catch (sttError) {
          console.warn('All STT methods failed, using text fallback:', sttError);
          text = req.body.text || 'Voice input received but transcription failed';
        }
      }

      // Ensure we have some text to work with
      if (!text || text.trim().length === 0) {
        text = mode === 'voice' ? 'I received your voice message' : 'Hello, how are you feeling?';
      }

      console.log('Final processed text:', text);

      // Phase 3: Advanced Emotion Detection
      let emotionResult;
      const detectionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
      
      if (mode === 'voice' && audioPath && fs.existsSync(audioPath)) {
        // Combined text + voice emotion detection
        console.log('‚ö° Phase 3: Running OPTIMIZED combined emotion detection...');
        const combinedResult = await detectCombinedEmotion(text, audioPath, detectionLanguage);
        
        // Also get text emotion with context for voice mode
        console.log('üîÑ Calling detectEmotionFromText for context extraction...');
        const textWithContext = await detectEmotionFromText(text, detectionLanguage);
        
        emotionResult = {
          emotion: combinedResult.combined.emotion,
          confidence: combinedResult.combined.confidence,
          text_emotion: combinedResult.text.emotion,
          voice_emotion: combinedResult.voice.emotion,
          context: textWithContext.context || [],
          method: 'combined'
        };
        
        console.log(`üìä Combined emotion with context: ${emotionResult.emotion} (${emotionResult.confidence.toFixed(3)}) - Context: [${emotionResult.context.join(', ') || 'no context'}]`);
        
        // Clean up temp audio file
        try {
          fs.unlinkSync(audioPath);
        } catch (cleanupError) {
          console.warn('Failed to clean up temp audio file:', cleanupError);
        }
      } else {
        // Text-only emotion detection
        console.log('Phase 3: Running text emotion detection...');
        const textResult = await detectEmotionFromText(text, detectionLanguage);
        emotionResult = {
          emotion: textResult.emotion,
          confidence: textResult.confidence,
          context: textResult.context || [],
          method: 'text-only'
        };
      }

      console.log('Phase 3 Emotion Detection Result:', emotionResult);

      // Phase 4: Parse conversation history for context
      let conversationHistory: ConversationHistory[] = [];
      try {
        if (history) {
          const parsedHistory = typeof history === 'string' ? JSON.parse(history) : history;
          conversationHistory = Array.isArray(parsedHistory) ? parsedHistory : [];
          console.log('Phase 4: Parsed conversation history length:', conversationHistory.length);
        }
      } catch (historyError) {
        console.warn('Phase 4: Failed to parse conversation history:', historyError);
        conversationHistory = [];
      }

      // Phase 4: Generate conversational response using Llama-2 + TTS
      try {
        console.log('Phase 4: Attempting Llama-2 conversational response generation...');
        const responseResult = await generateConversationalResponse({
          text,
          emotion: emotionResult.emotion,
          language: detectionLanguage,
          history: conversationHistory,
          userContext: {
            // Add user context if available from session
            preferences: ['empathetic', 'supportive']
          }
        });

        console.log('Phase 4: Llama response generated successfully');
        console.log('Phase 4: TTS audio available:', !!responseResult.audioBase64);

        res.json({ 
          transcription: text, 
          emotion: emotionResult.emotion,
          confidence: emotionResult.confidence,
          detectedEmotion: emotionResult.emotion, // For backward compatibility
          response: responseResult.response,
          mode: mode || 'text',
          language: detectionLanguage,
          emotionDetails: emotionResult,
          // Phase 4: New fields
          audioBase64: responseResult.audioBase64, // TTS audio for avatar
          conversational: true,
          model: responseResult.metadata?.model,
          processingTime: responseResult.metadata?.processingTime,
          historyLength: responseResult.metadata?.historyLength
        });

      } catch (llamaError) {
        console.warn('Phase 4: Llama response failed, using fallback:', llamaError);
        
        // Fallback to existing response generation
        const supportResponse = generateEmotionalSupportResponse(
          text, 
          emotionResult.emotion, 
          emotionResult.confidence,
          detectionLanguage
        );

        res.json({ 
          transcription: text, 
          emotion: emotionResult.emotion,
          confidence: emotionResult.confidence,
          detectedEmotion: emotionResult.emotion, // For backward compatibility
          response: supportResponse,
          mode: mode || 'text',
          language: detectionLanguage,
          emotionDetails: emotionResult,
          // Phase 4: Indicate fallback was used
          conversational: false,
          fallbackUsed: true,
          error: llamaError instanceof Error ? llamaError.message : 'Llama response failed'
        });
      }
    } catch (error) {
      console.error("Error processing emotional support request:", error);
      res.status(500).json({ 
        error: 'Processing failed',
        details: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  });

  // Guardian dashboard routes (TODO: Implement with MongoDB)
  app.get('/api/guardian/children', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      // const guardianId = req.user?.claims?.sub;
      // const children = await mongoStorage.getGuardianChildren(guardianId);
      res.json([]); // Temporary: return empty array
    } catch (error) {
      console.error("Error fetching guardian children:", error);
      res.status(500).json({ message: "Failed to fetch children" });
    }
  });

  app.post('/api/guardian/add-child', tokenBasedAuth, async (req: AuthenticatedRequest, res: Response) => {
    try {
      // const guardianId = req.user?.claims?.sub;
      // const { childId, relationship } = req.body;
      // const guardianship = await mongoStorage.createGuardianship(guardianId, childId, relationship);
      res.json({ message: "Guardian functionality coming soon" }); // Temporary
    } catch (error) {
      console.error("Error adding child:", error);
      res.status(500).json({ message: "Failed to add child" });
    }
  });

  // Create HTTP server
  const httpServer = createServer(app);

  // WebSocket server for real-time features
  const wss = new WebSocketServer({ server: httpServer, path: '/ws' });

  wss.on('connection', async (ws: WebSocket, req) => {
    console.log('üîó New WebSocket connection from:', req.headers['user-agent']?.substring(0, 50));
    
    // Handle authentication
    let userId = null;
    let authAttempted = false;
    try {
      // Check query params for token
      const url = new URL(req.url || '', 'http://localhost');
      let token = url.searchParams.get('token');
      
      // Also check for Authorization header
      if (!token && req.headers.authorization) {
        const authHeader = req.headers.authorization;
        if (authHeader && authHeader.startsWith('Bearer ')) {
          token = authHeader.substring(7); // Remove "Bearer " prefix
        }
      }
      
      if (token && token.length > 0 && token !== 'null' && token !== 'undefined') {
        authAttempted = true;
        console.log('üîë Attempting WebSocket authentication with token:', token.substring(0, 8) + '...');
        
        // Verify the token (user ID)
        const user = await mongoStorage.getUser(token);
        if (user) {
          userId = user.id;
          console.log(`‚úÖ WebSocket authenticated for user: ${userId}`);
          
          // Attach user to WebSocket object for future reference
          (ws as any).user = user;
        } else {
          console.warn('‚ùå Invalid WebSocket token, user not found');
          ws.close(1008, 'Authentication failed - user not found');
          return;
        }
      } else {
        console.warn('‚ö†Ô∏è No valid token provided for WebSocket connection');
        // Still allow connection for non-authenticated features but log it
        console.log('üîì Allowing unauthenticated WebSocket connection');
      }
    } catch (error) {
      console.error('WebSocket authentication error:', error);
    }

    ws.on('message', async (data) => {
      try {
        const message = JSON.parse(data.toString());
        
        // Handle auth messages
        if (message.type === 'auth') {
          const token = message.data?.token;
          if (token) {
            try {
              const user = await mongoStorage.getUser(token);
              if (user) {
                userId = user.id;
                (ws as any).user = user;
                console.log(`WebSocket authenticated via message for user: ${userId}`);
                
                // Send confirmation
                if (ws.readyState === WebSocket.OPEN) {
                  ws.send(JSON.stringify({
                    type: 'auth_success',
                    data: { userId }
                  }));
                }
              }
            } catch (error) {
              console.error('WebSocket auth message error:', error);
              if (ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                  type: 'auth_error',
                  data: { message: 'Authentication failed' }
                }));
              }
            }
          }
          return; // Don't process further for auth messages
        }
        else if (message.type === 'speech_practice') {
          // Handle real-time speech practice feedback
          ws.send(JSON.stringify({
            type: 'speech_feedback',
            data: { status: 'processing' }
          }));
        } else if (message.type === 'chat_message') {
          // Handle real-time chat
          const emotionAnalysis = await analyzeEmotion(message.content);
          
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({
              type: 'ai_response',
              data: {
                response: emotionAnalysis.response,
                emotion: emotionAnalysis.emotion,
                supportType: emotionAnalysis.supportType
              }
            }));
          }
        } else if (message.type === 'emotional-support') {
          // Handle emotional support chat via WebSocket
          try {
            const { text, language, audio } = message;
            let inputText = text;

            // Handle audio if present
            if (audio) {
              try {
                const audioBuffer = Buffer.from(audio, 'base64');
                const whisperLanguage = language?.startsWith('ur') ? 'ur' : 'en';
                inputText = await transcribeAudio(audioBuffer, whisperLanguage);
              } catch (sttError) {
                console.warn('WebSocket STT failed, using text input:', sttError);
                inputText = text || 'Could not transcribe audio';
              }
            }

            if (!inputText?.trim()) {
              if (ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                  type: 'error',
                  data: { message: 'No input provided' }
                }));
              }
              return;
            }

            // Process emotion detection
            let finalEmotion = { emotion: 'neutral', confidence: 0.5 };
            try {
              const emotionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
              const textEmotion = await detectEmotionFromText(inputText, emotionLanguage);
              
              if (audio) {
                try {
                  // Save audio buffer to temporary file for emotion detection
                  const audioBuffer = Buffer.from(audio, 'base64');
                  const tempDir = path.join(process.cwd(), 'temp');
                  if (!fs.existsSync(tempDir)) {
                    fs.mkdirSync(tempDir, { recursive: true });
                  }
                  const tempAudioPath = path.join(tempDir, `ws_audio_${Date.now()}.wav`);
                  fs.writeFileSync(tempAudioPath, audioBuffer);
                  
                  // Use OPTIMIZED combined emotion detection
                  const combinedResult = await detectCombinedEmotion(inputText, tempAudioPath, emotionLanguage);
                  finalEmotion = {
                    emotion: combinedResult.combined.emotion,
                    confidence: combinedResult.combined.confidence
                  };
                  
                  // Clean up temp file
                  try {
                    fs.unlinkSync(tempAudioPath);
                  } catch (cleanupError) {
                    console.warn('Failed to clean up temp audio file:', cleanupError);
                  }
                } catch (voiceError) {
                  finalEmotion = {
                    emotion: textEmotion.emotion,
                    confidence: textEmotion.confidence
                  };
                }
              } else {
                finalEmotion = {
                  emotion: textEmotion.emotion,
                  confidence: textEmotion.confidence
                };
              }
            } catch (emotionError) {
              console.warn('WebSocket emotion detection failed:', emotionError);
            }

            // Generate response
            let finalResponse = '';
            try {
              const emotionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
              finalResponse = await generateEmotionalResponse(finalEmotion.emotion, inputText, emotionLanguage);
            } catch (error) {
              finalResponse = 'I understand. Please tell me more about how you\'re feeling.';
            }

            // Send response via WebSocket
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'emotional-support-response',
                response: finalResponse,
                emotion: finalEmotion,
                transcription: inputText
              }));
            }
          } catch (error) {
            console.error('WebSocket emotional support error:', error);
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'error',
                data: { message: 'Failed to process emotional support request' }
              }));
            }
          }
        } else if (message.type === 'emotional-support-voice') {
          // Handle emotional support VOICE mode via WebSocket
          try {
            const { text, language, audio, requestTTS, voiceSettings } = message;
            let inputText = text;

            // Handle audio if present
            if (audio) {
              try {
                const audioBuffer = Buffer.from(audio, 'base64');
                const whisperLanguage = language?.startsWith('ur') ? 'ur' : 'en';
                inputText = await transcribeAudio(audioBuffer, whisperLanguage);
              } catch (sttError) {
                console.warn('WebSocket Voice STT failed, using text input:', sttError);
                inputText = text || 'Could not transcribe audio';
              }
            }

            if (!inputText?.trim()) {
              if (ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                  type: 'error',
                  data: { message: 'No voice input provided' }
                }));
              }
              return;
            }

            // Enhanced emotion detection for voice mode
            let finalEmotion = { emotion: 'neutral', confidence: 0.5 };
            try {
              const emotionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
              const textEmotion = await detectEmotionFromText(inputText, emotionLanguage);
              
              if (audio) {
                try {
                  // Save audio buffer to temporary file for emotion detection
                  const audioBuffer = Buffer.from(audio, 'base64');
                  const tempDir = path.join(process.cwd(), 'temp');
                  if (!fs.existsSync(tempDir)) {
                    fs.mkdirSync(tempDir, { recursive: true });
                  }
                  const tempAudioPath = path.join(tempDir, `ws_voice_audio_${Date.now()}.wav`);
                  fs.writeFileSync(tempAudioPath, audioBuffer);
                  
                  // Use OPTIMIZED combined emotion detection
                  const combinedResult = await detectCombinedEmotion(inputText, tempAudioPath, emotionLanguage);
                  finalEmotion = {
                    emotion: combinedResult.combined.emotion,
                    confidence: combinedResult.combined.confidence
                  };
                  console.log('Voice WebSocket: Combined emotion detected:', finalEmotion);
                  
                  // Clean up temp file
                  try {
                    fs.unlinkSync(tempAudioPath);
                  } catch (cleanupError) {
                    console.warn('Failed to clean up temp audio file:', cleanupError);
                  }
                } catch (voiceError) {
                  console.warn('Voice WebSocket: Audio emotion detection failed, using text-only');
                  finalEmotion = {
                    emotion: textEmotion.emotion,
                    confidence: textEmotion.confidence
                  };
                }
              } else {
                finalEmotion = {
                  emotion: textEmotion.emotion,
                  confidence: textEmotion.confidence
                };
              }
            } catch (emotionError) {
              console.warn('WebSocket voice emotion detection failed:', emotionError);
            }

            // Generate empathetic response for voice mode
            let finalResponse = '';
            try {
              const emotionLanguage = language?.startsWith('ur') ? 'ur' : 'en';
              finalResponse = await generateEmotionalResponse(finalEmotion.emotion, inputText, emotionLanguage);
              console.log('Voice WebSocket: Generated response for', finalEmotion.emotion);
            } catch (error) {
              console.warn('Voice WebSocket: Response generation failed, using fallback');
              finalResponse = language?.startsWith('ur') 
                ? 'ŸÖ€å⁄∫ ÿ≥ŸÖÿ¨⁄æ ÿ±€Åÿß €ÅŸà⁄∫€î ÿ®ÿ±ÿß€Å ⁄©ÿ±ŸÖ ŸÖÿ¨⁄æ€í ÿ®ÿ™ÿßÿ¶€å⁄∫ ⁄©€Å ÿ¢Ÿæ ⁄©€åÿ≥ÿß ŸÖÿ≠ÿ≥Ÿàÿ≥ ⁄©ÿ± ÿ±€Å€í €Å€å⁄∫€î' 
                : 'I understand. Please tell me more about how you\'re feeling.';
            }

            // TODO: Add Text-to-Speech (TTS) generation here
            let audioResponse = null;
            if (requestTTS) {
              try {
                // Placeholder for TTS implementation
                // audioResponse = await generateTTS(finalResponse, language, voiceSettings);
                console.log('TTS requested but not implemented yet');
              } catch (ttsError) {
                console.warn('TTS generation failed:', ttsError);
              }
            }

            // Send voice response via WebSocket
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'emotional-support-voice-response',
                response: finalResponse,
                emotion: finalEmotion,
                transcription: inputText,
                audioBlob: audioResponse, // Will be null until TTS is implemented
                voiceMode: true
              }));
            }
          } catch (error) {
            console.error('WebSocket emotional support voice error:', error);
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'error',
                data: { message: 'Failed to process voice emotional support request' }
              }));
            }
          }
        }
      } catch (error) {
        console.error('WebSocket message error:', error);
        if (ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({
            type: 'error',
            data: { message: 'Failed to process message' }
          }));
        }
      }
    });

    ws.on('close', () => {
      console.log('WebSocket connection closed');
    });
  });

  return httpServer;
}
