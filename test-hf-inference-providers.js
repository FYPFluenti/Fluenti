// Comprehensive HuggingFace Inference Provider Test
// Tests multiple models and providers to diagnose availability issues

import { HfInference } from '@huggingface/inference';
import { config } from 'dotenv';

config();

async function testInferenceProviders() {
    console.log('ü§ó HuggingFace Inference Provider Comprehensive Test');
    console.log('='.repeat(60));
    
    const apiKey = process.env.HUGGINGFACE_API_KEY;
    
    if (!apiKey) {
        console.error('‚ùå HUGGINGFACE_API_KEY not found');
        return;
    }
    
    console.log(`‚úÖ Token: ${apiKey.substring(0,6)}...${apiKey.substring(apiKey.length-4)} (${apiKey.length} chars)`);
    console.log(`‚úÖ Token format: ${apiKey.startsWith('hf_') ? 'Valid' : 'Invalid'}\n`);
    
    const hf = new HfInference(apiKey);
    
    // Test different model categories and providers
    const testCases = [
        {
            name: 'Text Classification (Light)',
            test: async () => {
                return await hf.textClassification({
                    model: 'cardiffnlp/twitter-roberta-base-sentiment-latest',
                    inputs: 'I am happy'
                });
            }
        },
        {
            name: 'Emotion Classification (FLUENTI)',
            test: async () => {
                return await hf.textClassification({
                    model: 'j-hartmann/emotion-english-distilroberta-base',
                    inputs: 'I feel anxious'
                });
            }
        },
        {
            name: 'Text Generation (GPT-2)',
            test: async () => {
                return await hf.textGeneration({
                    model: 'gpt2',
                    inputs: 'Hello',
                    parameters: { max_new_tokens: 5 }
                });
            }
        },
        {
            name: 'Speech Recognition (Whisper Tiny)',
            test: async () => {
                // Create minimal audio blob for testing
                const silentAudio = new Uint8Array(1024).fill(0);
                const audioBlob = new Blob([silentAudio], { type: 'audio/wav' });
                
                return await hf.automaticSpeechRecognition({
                    model: 'openai/whisper-tiny',
                    data: audioBlob
                });
            }
        },
        {
            name: 'Speech Recognition (Whisper Base)',
            test: async () => {
                const silentAudio = new Uint8Array(1024).fill(0);
                const audioBlob = new Blob([silentAudio], { type: 'audio/wav' });
                
                return await hf.automaticSpeechRecognition({
                    model: 'openai/whisper-base',
                    data: audioBlob
                });
            }
        },
        {
            name: 'Alternative STT Model',
            test: async () => {
                const silentAudio = new Uint8Array(1024).fill(0);
                const audioBlob = new Blob([silentAudio], { type: 'audio/wav' });
                
                return await hf.automaticSpeechRecognition({
                    model: 'facebook/wav2vec2-large-960h-lv60-self',
                    data: audioBlob
                });
            }
        }
    ];
    
    const results = [];
    
    for (const testCase of testCases) {
        console.log(`üß™ Testing: ${testCase.name}`);
        
        try {
            const startTime = Date.now();
            const result = await testCase.test();
            const duration = Date.now() - startTime;
            
            console.log(`‚úÖ SUCCESS (${duration}ms)`);
            
            if (testCase.name.includes('Classification')) {
                const topResult = Array.isArray(result) ? result[0] : result;
                console.log(`   Result: ${topResult.label} (${(topResult.score * 100).toFixed(1)}%)`);
            } else if (testCase.name.includes('Generation')) {
                console.log(`   Generated: "${result.generated_text?.substring(0, 50)}..."`);
            } else if (testCase.name.includes('Speech')) {
                console.log(`   Transcription: "${result.text || 'No speech detected'}"`);
            }
            
            results.push({ name: testCase.name, status: 'SUCCESS', duration });
            
        } catch (error) {
            console.log(`‚ùå FAILED: ${error.message}`);
            
            // Analyze error types
            if (error.message.includes('No Inference Provider')) {
                console.log(`   ‚Üí Provider unavailable (temporary server issue)`);
            } else if (error.message.includes('rate limit')) {
                console.log(`   ‚Üí Rate limit reached`);
            } else if (error.message.includes('401')) {
                console.log(`   ‚Üí Authentication issue`);
            } else if (error.message.includes('timeout')) {
                console.log(`   ‚Üí Request timeout`);
            } else {
                console.log(`   ‚Üí Other error: ${error.message.substring(0, 100)}`);
            }
            
            results.push({ name: testCase.name, status: 'FAILED', error: error.message });
        }
        
        console.log(''); // Empty line for readability
        
        // Add delay between requests to avoid rate limiting
        await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    // Summary
    console.log('üìä Test Results Summary:');
    console.log('='.repeat(40));
    
    const successful = results.filter(r => r.status === 'SUCCESS');
    const failed = results.filter(r => r.status === 'FAILED');
    
    console.log(`‚úÖ Successful: ${successful.length}/${results.length}`);
    console.log(`‚ùå Failed: ${failed.length}/${results.length}`);
    
    if (successful.length > 0) {
        console.log('\n‚úÖ Working Models:');
        successful.forEach(r => {
            console.log(`   ‚Ä¢ ${r.name} (${r.duration}ms)`);
        });
    }
    
    if (failed.length > 0) {
        console.log('\n‚ùå Failed Models:');
        failed.forEach(r => {
            console.log(`   ‚Ä¢ ${r.name}: ${r.error.substring(0, 60)}...`);
        });
    }
    
    // Recommendations
    console.log('\nüí° Recommendations:');
    if (successful.length === 0) {
        console.log('   ‚Üí All models failed - check token validity or try later');
        console.log('   ‚Üí HuggingFace servers may be experiencing issues');
    } else if (failed.some(r => r.name.includes('Speech'))) {
        console.log('   ‚Üí STT models may be unavailable - use text input as fallback');
        console.log('   ‚Üí Consider local STT solutions for production');
    } else {
        console.log('   ‚Üí Some models working - inference providers are partially available');
    }
    
    // Test FLUENTI integration
    console.log('\nüöÄ Testing FLUENTI Integration:');
    try {
        const response = await fetch('http://localhost:3000/api/test-emotional-support', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text: 'I am testing the system', language: 'en' })
        });
        
        if (response.ok) {
            const result = await response.json();
            console.log('‚úÖ FLUENTI API: Working perfectly');
            console.log(`   Emotion detected: ${result.emotion.emotion} (${(result.emotion.score * 100).toFixed(1)}%)`);
        } else {
            console.log(`‚ùå FLUENTI API: HTTP ${response.status}`);
        }
    } catch (error) {
        console.log(`‚ö†Ô∏è FLUENTI API: ${error.message}`);
    }
}

// Run the comprehensive test
testInferenceProviders().catch(console.error);
